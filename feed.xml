<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
<generator uri="http://jekyllrb.com" version="3.7.3">Jekyll</generator>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/feed.xml" rel="self" type="application/atom+xml" />
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/" rel="alternate" type="text/html" />
<updated>2018-03-17T23:29:21+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/</id>
<subtitle>Jose Estudillo's Blog. Software engineering and technology blog.</subtitle>
<author>
<name>Jose Estudillo</name>
<email>jose@estudillo.me</email>
</author>
<entry>
<title>Creating a kafka cluster with docker</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/2017/08/27/creating-kafka-cluster-with-docker/" rel="alternate" type="text/html" title="Creating a kafka cluster with docker" />
<published>2017-08-27T00:00:00+01:00</published>
<updated>2017-08-27T00:00:00+01:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/2017/08/27/creating-kafka-cluster-with-docker</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/2017/08/27/creating-kafka-cluster-with-docker/">&lt;h1&gt;Creating a kafka cluster with docker&lt;/h1&gt;

&lt;p&gt;A local &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt; cluster will help to develop producer and consumers, allowing to test different scenarios specially when it comes to HA. In this article I&amp;#39;ll show how to create a kafka cluster using &lt;a href=&quot;https://www.docker.com/&quot;&gt;docker&lt;/a&gt; and &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;docker-compose&lt;/a&gt;.  &lt;/p&gt;

&lt;h2&gt;Defining kafka image: Dockerfile&lt;/h2&gt;

&lt;p&gt;For the creation of the &lt;a href=&quot;https://www.docker.com/&quot;&gt;docker&lt;/a&gt; image we will use the version &lt;a href=&quot;http://www-eu.apache.org/dist/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz&quot;&gt;0.11.0.0&lt;/a&gt; as specified in the code below in the environment var &lt;code&gt;KAFKA_BIN&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Dockerfile&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-Dockerfile&quot; data-lang=&quot;Dockerfile&quot;&gt;FROM centos:7
MAINTAINER jose@estudillo.me

ENV KAFKA_BIN=http://www-eu.apache.org/dist/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz

RUN yum install -y wget java-1.8.0-openjdk \
    &amp;amp;&amp;amp; cd /tmp &amp;amp;&amp;amp; wget -q $KAFKA_BIN \
    &amp;amp;&amp;amp; export K_TAR=/tmp/$(ls kafka* | head -1) \
    &amp;amp;&amp;amp; mkdir -p /opt/apache/kafka/ &amp;amp;&amp;amp; tar -zxf $K_TAR -C /opt/apache/kafka/ \
    &amp;amp;&amp;amp; cd /opt/apache/kafka &amp;amp;&amp;amp; ln -s $(ls) current \
    &amp;amp;&amp;amp; rm -rf $K_TAR

ENV KAFKA_HOME /opt/apache/kafka/current
ENV PATH $PATH:$KAFKA_HOME/bin

ADD resources /home/kafka

RUN groupadd -r kafka \
    &amp;amp;&amp;amp; useradd -r -g kafka kafka \
    &amp;amp;&amp;amp; mkdir -p /home/kafka \
    &amp;amp;&amp;amp; chown -R kafka:kafka /home/kafka \
    &amp;amp;&amp;amp; chmod -R +x /home/kafka/scripts \
    &amp;amp;&amp;amp; mkdir -p /var/log/kafka \
    &amp;amp;&amp;amp; chown -R kafka:kafka /var/log/kafka \
    &amp;amp;&amp;amp; mkdir -p /etc/kafka \
    &amp;amp;&amp;amp; chown -R kafka:kafka /etc/kafka

USER kafka

CMD /home/kafka/scripts/run.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;Dockerimage&lt;/code&gt; will download the &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt; binaries and place then into &lt;code&gt;/opt/apache/kafka&lt;/code&gt; and link the current version to &lt;code&gt;/opt/apache/kafka/current&lt;/code&gt;, after that it add it into the &lt;code&gt;PATH&lt;/code&gt; and create the required directories that need to be owned by the &lt;code&gt;kafka&lt;/code&gt; user.&lt;/p&gt;

&lt;p&gt;In order to configure and start the broker properly, &lt;code&gt;CMD&lt;/code&gt; needs to call a bash script that must be added to the image &lt;code&gt;ADD resources /home/kafka&lt;/code&gt;, putting all the content from the local directory &lt;code&gt;resources&lt;/code&gt; in the image directory &lt;code&gt;/home/kafka&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;resources/scripts/run.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; &amp;gt; /etc/kafka/broker.properties
broker.id=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hostname&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;s/[^0-9]*//g&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
port=9092
log.dir=/var/log/kafka
zookeeper.connect=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KAFKA_ZOOKEEPER_HOST&lt;/span&gt;:&lt;span class=&quot;p&quot;&gt;=zookeeper&lt;/span&gt;:2181&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
host.name=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hostname&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
advertised.host.name=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hostname&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
advertised.host.port=9092
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF

&lt;/span&gt;kafka-server-start.sh /etc/kafka/broker.properties
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For this to work we require:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Every container created from this image must contain a number in the hostname, so it can be used as &lt;code&gt;broker.id&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Kafka requires &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Zookeeper&lt;/a&gt; to be able to work, the script will assume that the hostname for this is &lt;code&gt;zookeeper&lt;/code&gt;, but this value can be also specified in the env var &lt;code&gt;KAFKA_ZOOKEEPER_HOST&lt;/code&gt; (i.c. `zoo1:2181,zoo2:2181,zoo3:2181)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Creating the kafka image from the Dockerfile&lt;/h2&gt;

&lt;p&gt;In this example I use my own namespace (&lt;code&gt;joseestudillo&lt;/code&gt;) but this is not required and can be omitted. I also add the version &lt;code&gt;latest&lt;/code&gt; to follow docker image naming standards.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker build &lt;span class=&quot;nt&quot;&gt;--tag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;joseestudillo/kafka:0.0.1&quot;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
docker tag joseestudillo/kafka:0.0.1 joseestudillo/kafka:latest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Creating the cluster: docker compose&lt;/h2&gt;

&lt;p&gt;Having the kafka image in our system we are ready to create a cluster. For &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Zookeeper&lt;/a&gt; we will use the official image from &lt;a href=&quot;https://hub.docker.com/_/zookeeper/&quot;&gt;docker hub&lt;/a&gt;. In the docker compose example I&amp;#39;ll create a 3 nodes kafka cluster, but any number of nodes can be added by adding a new entry and changing the name/hostname.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-YAML&quot; data-lang=&quot;YAML&quot;&gt;version: '2.1'
services:
  zookeeper:
    hostname: zookeeper
    image: zookeeper:latest
    environment:
      ZOO_MY_ID: 1
    restart: always
    healthcheck:
        test: [&quot;CMD&quot;, &quot;zkServer.sh&quot;, &quot;status&quot;]

  kafka1:
    image: joseestudillo/kafka:latest
    hostname: kafka1
    environment:
      KAFKA_ZOOKEEPER_HOST: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      zookeeper:
        condition: service_healthy

  kafka2:
    image: joseestudillo/kafka:latest
    hostname: kafka2
    environment:
      KAFKA_ZOOKEEPER_HOST: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - kafka1

  kafka3:
    image: joseestudillo/kafka:latest
    hostname: kafka3
    environment:
      KAFKA_ZOOKEEPER_HOST: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - kafka1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In they YAML, I&amp;#39;ve defined a single node zookeeper (examples with a higher number of nodes can be found in docker hub). Notice that &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Zookeeper&lt;/a&gt; must be running to be able to create a kafka cluster, to guarantee this, we will make the first &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt; node (&lt;code&gt;kafka1&lt;/code&gt;) depend on the &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Zookeeper&lt;/a&gt; container, then the rest of the &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt; nodes will depend of the first one that we will use as advertised host.&lt;/p&gt;

&lt;h2&gt;Running the cluster&lt;/h2&gt;

&lt;p&gt;Once the kafka image is on the system (check with &lt;code&gt;docker images&lt;/code&gt;), we can launch the cluster using: &lt;code&gt;docker-compose up&lt;/code&gt; that will show the logs from all the running containers. The status of the containers can be checked with &lt;code&gt;docker-compose ps&lt;/code&gt; that as the rest of the docker compose commands, but be run from the directory where &lt;code&gt;docker-compose.yml&lt;/code&gt; is placed, or point explicitly to it.&lt;/p&gt;

&lt;p&gt;The cluster then can be operated from any of its nodes: &lt;code&gt;docker-compose exec &amp;lt;container name in the docker compose file&amp;gt; bash&lt;/code&gt;&lt;/p&gt;
</content>
<summary>Creating a kafka cluster with docker</summary>
</entry>
<entry>
<title>Hosting an apache server in Openshift with a godaddy hosted domain</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/2015/08/04/hosting-apache-server-openshift-godaddy-domain/" rel="alternate" type="text/html" title="Hosting an apache server in Openshift with a godaddy hosted domain" />
<published>2015-08-04T00:00:00+01:00</published>
<updated>2015-08-04T00:00:00+01:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/2015/08/04/hosting-apache-server-openshift-godaddy-domain</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/2015/08/04/hosting-apache-server-openshift-godaddy-domain/">&lt;h1&gt;Hosting an apache server in Openshift with a godaddy hosted domain&lt;/h1&gt;

&lt;p&gt;In this article I&amp;#39;ll show how to point an existing domain hosted in godaddy to an apache server running in Openshift, to do so I&amp;#39;ll use the following generic URLs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Subdomain under you already registered domain: &lt;code&gt;http://SUBDOMAIN.DOMAIN.com&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;URL to the apache server hosted in &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt;: &lt;code&gt;http://APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And I will also assume you have a free account in &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Creating an application&lt;/h2&gt;

&lt;p&gt;Once logged into &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt; go to: &lt;strong&gt;Applications -&amp;gt; Add Application...&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In this case I will focus in creating a simple apache server. Configuring any other type of server should work in the same way. The apache server isn&amp;#39;t offered as an option, but any server that can host PHP will work (for example: PHP 5.3, PHP 5.4).&lt;/p&gt;

&lt;p&gt;During the instantiation process, we will be asked to create an URL for the new application, in our case this will be: &lt;code&gt;http://APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com&lt;/code&gt;. Unless you have specific needs, the rest of the parameters can be left as they are. A git repository can be given to obtaion the content, otherwise, one will be created for every application.&lt;/p&gt;

&lt;h2&gt;Uploading files to the application using git&lt;/h2&gt;

&lt;p&gt;In the right side hand of the application configuration menu, there is a box that displays the git repository associated to the app, for this example it would look like &lt;code&gt;ssh://ID@APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com/~/git/APPNAME.git/&lt;/code&gt; using this URL we can clone the git repository from the CLI:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
git clone ssh://[ID]@APP&lt;em&gt;NAME-OPENSHIFT&lt;/em&gt;DOMAIN_NAME.rhcloud.com/~/git/APPNAME.git/
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Once it has been cloned, we can place the required files into the directory &lt;code&gt;APPNAME&lt;/code&gt;. The last step will be uploading the files, this can be done using the commands below:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
git add --all
git commit -m &amp;quot;&lt;code&gt;date&lt;/code&gt;&amp;quot;
git push origin
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Notice that for this to work you will need credentials, the easiest way to do it is having your public shh key configured in &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt;. This is outside the scope of this article, so as a quick tip, &lt;code&gt;ssh-keygen -t rsa -b 4096 -C &amp;quot;your@email.com&amp;quot;&lt;/code&gt; will generate the public key and &lt;code&gt;cat ~/.ssh/id_rsa.pub&lt;/code&gt; will display it.&lt;/p&gt;

&lt;h3&gt;Setting the alias domain&lt;/h3&gt;

&lt;p&gt;From the application configuration page, right next to the application&amp;#39;s URL, there is a link called &lt;strong&gt;change&lt;/strong&gt;, clicking on it will take you to a menu where you can see two values:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Application URL&lt;/strong&gt;: is the actual URL app, it should look like &lt;code&gt;http://APP_NAME-DOMAIN_NAME.rhcloud.com&lt;/code&gt; (as defined before) and&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Domain Name&lt;/strong&gt;: which is the domain that will be pointing to this app, being in the case &lt;code&gt;SUBDOMAIN.DOMAIN.com&lt;/code&gt;. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this is setup, no further configuration is required on the &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt; side.&lt;/p&gt;

&lt;h3&gt;Configuring the domain in Godaddy&lt;/h3&gt;

&lt;p&gt;To point our domain to a &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt;&amp;#39;s application we need two things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;redirect DOMAIN.com to SUBDOMAIN.DOMAIN.com&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;add a CNAME entry to point SUBDOMAIN.DOMAIN.com to the &lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt; URL.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The redirection is done using forwarding at domain level (no subdomain!) so clicking in &lt;strong&gt;manage&lt;/strong&gt; under the forwarding category should allow you to add an entry:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Forward To&lt;/strong&gt;: http://SUBDOMAIN.DOMAIN.com&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Redirect Type&lt;/strong&gt;: 301 (Permanent)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Forward Settings&lt;/strong&gt;: Forward only&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adding the CName entry is done from a different tab, &lt;strong&gt;DNS ZONE FILE&lt;/strong&gt;, where you must check that under:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A (Host)&lt;/strong&gt; : there is no entries for the subdomain you want to redirect, and, in&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;CName (Alias)&lt;/strong&gt;: you add the entry:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Record Type&lt;/em&gt;: CNAME (alias)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Host&lt;/em&gt;: SUBDOMAIN&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Points To&lt;/em&gt;: http://APP&lt;em&gt;NAME-OPENSHIFT&lt;/em&gt;DOMAIN_NAME.rhcloud.com&lt;/li&gt;
&lt;li&gt;&lt;em&gt;TTL&lt;/em&gt;: 1 hour&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you got to this point you are all setup, after waiting a few minutes (this may vary) the page will be ready to use.&lt;/p&gt;
</content>
<summary>Hosting an apache server in Openshift with a godaddy hosted domain</summary>
</entry>
<entry>
<title>Exporting/Importing keyboard shortcuts in Linux Mint</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/linux/mint/2015/06/01/exporting-keybindings-linux-mint/" rel="alternate" type="text/html" title="Exporting/Importing keyboard shortcuts in Linux Mint" />
<published>2015-06-01T00:00:00+01:00</published>
<updated>2015-06-01T00:00:00+01:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/linux/mint/2015/06/01/exporting-keybindings-linux-mint</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/linux/mint/2015/06/01/exporting-keybindings-linux-mint/">&lt;h1&gt;Exporting/Importing keyboard shortcuts in Linux Mint (Cinnamon)&lt;/h1&gt;

&lt;p&gt;To check the configuration of &lt;a href=&quot;http://www.linuxmint.com/&quot;&gt;Linux Mint Cinnamon Edition&lt;/a&gt; we will need the command &lt;code&gt;dconf&lt;/code&gt;, in case it isn&amp;#39;t be installed, use &lt;code&gt;sudo apt-get install dconf-cli&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;See the current configuration&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;dconf dump /org/cinnamon/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will show all the entries under &lt;code&gt;/org/cinnamon/&lt;/code&gt; which means not all the entries will be related the the keyboard shorcuts configuration, you can get specific entries using the complete path in &lt;code&gt;dconf&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;Exporting the current configuration&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;dconf dump /org/cinnamon/ &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; keyboard-shortcuts-conf.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In my case, using &lt;a href=&quot;http://www.linuxmint.com/&quot;&gt;Linux Mint 17&lt;/a&gt;, I get many entries, but in this case we will only need the followings:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;settings-daemon/plugins/media-keys]
&lt;span class=&quot;nv&quot;&gt;terminal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Super&amp;gt;t'&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;screensaver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Super&amp;gt;l'&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Super&amp;gt;e'&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;settings-daemon/peripherals/keyboard]
numlock-state&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'on'&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;keybindings/custom-keybindings/custom0]
&lt;span class=&quot;nv&quot;&gt;binding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Super&amp;gt;w'&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/usr/bin/google-chrome-stable %U'&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Internet Browser'&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;keybindings]
custom-list&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'custom0'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;muffin/keybindings]
panel-run-dialog&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Alt&amp;gt;F2'&lt;/span&gt;, &lt;span class=&quot;s1&quot;&gt;'&amp;lt;Super&amp;gt;r'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;unmaximize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;@as &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;
toggle-fullscreen&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'F11'&lt;/span&gt;, &lt;span class=&quot;s1&quot;&gt;'&amp;lt;Super&amp;gt;f'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
toggle-maximized&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Super&amp;gt;m'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
move-to-workspace-left&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Shift&amp;gt;&amp;lt;Super&amp;gt;Left'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
move-to-workspace-right&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;Shift&amp;gt;&amp;lt;Super&amp;gt;Right'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Importing a configuration form a file&lt;/h2&gt;

&lt;p&gt;Using the file generated in the previous process &lt;code&gt;keyboard-shortcuts-conf.txt&lt;/code&gt; you can do the following&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;dconf load /org/cinnamon/ &amp;lt; keyboard-shortcuts-conf.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
<summary>Exporting/Importing keyboard shortcuts in Linux Mint (Cinnamon)</summary>
</entry>
<entry>
<title>Installing Oracle Database XE in CentOS 7</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/oracle/database/2014/12/24/installing-oracle-xe-database-centos-7/" rel="alternate" type="text/html" title="Installing Oracle Database XE in CentOS 7" />
<published>2014-12-24T00:00:00+00:00</published>
<updated>2014-12-24T00:00:00+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/oracle/database/2014/12/24/installing-oracle-xe-database-centos-7</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/oracle/database/2014/12/24/installing-oracle-xe-database-centos-7/">&lt;h1&gt;Installing Oracle Database XE in CentOS 7&lt;/h1&gt;

&lt;h2&gt;Getting the binaries&lt;/h2&gt;

&lt;p&gt;The binaries can be found in the link &lt;a href=&quot;http://www.oracle.com/technetwork/database/database-technologies/express-edition/downloads/index.html&quot;&gt;Oracle Database XE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;At the time of this writing the name of the file is &lt;code&gt;oracle-xe-11.2.0-1.0.x86_64.rpm.zip&lt;/code&gt; in linux this can be extracted using:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
unzip oracle-xe-11.2.0-1.0.x86_64.rpm.zip
{% endhighlight %}  &lt;/p&gt;

&lt;p&gt;Supposing the file have been extracted to &lt;code&gt;/tmp&lt;/code&gt; the rpm file will be at &lt;code&gt;/tmp/Disk1/oracle-xe-11.2.0-1.0.x86_64.rpm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;h1&gt;run as super user, su/sudo&lt;/h1&gt;

&lt;p&gt;rpm -Uvh oracle-xe-11.2.0-1.0.x86_64.rpm 
{% endhighlight %}  &lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;Preparing...                          ################################# [100%]
Updating / installing...
   1:oracle-xe-11.2.0-1.0             ################################# [100%]
Executing post-install steps...
sh: -c: line 0: syntax error near unexpected token `('
sh: -c: line 0: `echo ~(unknown)'
You must run '/etc/init.d/oracle-xe configure' as the root user to configure the database.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that despite the post-install script errors the installation is successful. I haven&amp;#39;t done much research about this yet. &lt;/p&gt;

&lt;p&gt;After installing the app run:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
/etc/init.d/oracle-xe configure #run as super user
{% endhighlight %}  &lt;/p&gt;

&lt;p&gt;Oracle Database XE has a webapp associated to it, be default the offered port is &lt;em&gt;8080&lt;/em&gt; but I will use &lt;em&gt;11521&lt;/em&gt; to avoid conflict with other applications. For the database listener, I&amp;#39;ll keep 1521.&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;[root@localhost Disk1]# /etc/init.d/oracle-xe configure

Oracle Database 11g Express Edition Configuration
-------------------------------------------------
This will configure on-boot properties of Oracle Database 11g Express 
Edition.  The following questions will determine whether the database should 
be starting upon system boot, the ports it will use, and the passwords that 
will be used for database accounts.  Press &amp;lt;Enter&amp;gt; to accept the defaults. 
Ctrl-C will abort.

Specify the HTTP port that will be used for Oracle Application Express [8080]:11521

Specify a port that will be used for the database listener [1521]:

Specify a password to be used for database accounts.  Note that the same
password will be used for SYS and SYSTEM.  Oracle recommends the use of 
different passwords for each database account.  This can be done after 
initial configuration:
Confirm the password:

Do you want Oracle Database 11g Express Edition to be started on boot (y/n) [y]:y

Starting Oracle Net Listener...Done
Configuring database...Done
Starting Oracle Database 11g Express Edition instance...Done
Installation completed successfully.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Managing the service&lt;/h2&gt;

&lt;p&gt;The service file is located in &lt;code&gt;/etc/init.d/oracle-xe&lt;/code&gt; and be started / stopped using:
{% highlight bash %}&lt;br&gt;
service oracle-xe start / service oracle-xe stop
{% endhighlight %}    &lt;/p&gt;

&lt;h2&gt;Opening Ports for external access&lt;/h2&gt;

&lt;p&gt;{% highlight bash %}
firewall-cmd --permanent --zone=public --add-port=11521/tcp
firewall-cmd --permanent --zone=public --add-port=1521/tcp
firewall-cmd --reload
{% endhighlight %}&lt;/p&gt;

&lt;h2&gt;First use&lt;/h2&gt;

&lt;p&gt;Assuming we are using the same box to access to the webapp, we could use &lt;a href=&quot;http://localhost:11521/&quot;&gt;localhost:11521&lt;/a&gt; and login as &lt;strong&gt;SYSTEM&lt;/strong&gt;. You&amp;#39;ll notice that even typing the right password, the login won&amp;#39;t be successful, just cancel the login, and you will be redirected to a different URL, this only happens the first time.&lt;/p&gt;

&lt;h3&gt;Creating a workspace&lt;/h3&gt;

&lt;p&gt;Once in APEX &lt;a href=&quot;http://localhost:11521/&quot;&gt;localhost:11521&lt;/a&gt; go to &lt;strong&gt;home -&amp;gt; Application express&lt;/strong&gt; and create a workspace (&lt;em&gt;Application express workspace&lt;/em&gt; it will be the name of the workspace)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%7B%7Bsite.baseurl%7D%7D/img/%7B%7Bpage.relImgFolder%7D%7D/create-workspace.png&quot; alt=&quot;creating oracle workspace&quot;&gt;&lt;/p&gt;

&lt;p&gt;then connect to it using the interface next to the previous one to access to the newly created workspace &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%7B%7Bsite.baseurl%7D%7D/img/%7B%7Bpage.relImgFolder%7D%7D/login-workspace.png&quot; alt=&quot;log into workspace&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Connecting from Java&lt;/h2&gt;

&lt;p&gt;To connect from Java the oracle database driver is required, the oracle drivers are not hosted in Maven, so the easiest way to get it is from: &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;/u01/app/oracle/product/11.2.0/xe/jdbc/lib/ojdbc6.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To install one the drives to make it accessible from Maven check [this][installLibMaven]. With Oracle driver added to the classpath, the connection URL for this example would look as follows:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;jdbc:oracle:thin:@localhost:1521:xe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And very quick chunk of code to test the connection:&lt;/p&gt;

&lt;p&gt;{% highlight java %}&lt;/p&gt;

&lt;p&gt;Class.forName(&amp;quot;oracle.jdbc.driver.OracleDriver&amp;quot;);
Connection conn = DriverManager.getConnection(&amp;quot;jdbc:oracle:thin:@localhost:1521:xe&amp;quot;, &amp;quot;dbuser&amp;quot;, &amp;quot;YOUR_PASSWORD&amp;quot;);
Statement statement = conn.createStatement();
ResultSet resultSet = statement.executeQuery(&amp;quot;SELECT 1 FROM Dual&amp;quot;);
if(resultSet.next()) {
    System.out.println(&amp;quot;Success&amp;quot;);
}&lt;/p&gt;

&lt;p&gt;{% endhighlight %}&lt;/p&gt;

&lt;p&gt;[installLibMaven]: {{site.baseurl}}{% post_url 2014-12-23-installing-third-party-jars-in-maven %}&lt;/p&gt;
</content>
<summary>Installing Oracle Database XE in CentOS 7</summary>
</entry>
<entry>
<title>Installing third party jars in Maven</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven/" rel="alternate" type="text/html" title="Installing third party jars in Maven" />
<published>2014-12-23T00:00:00+00:00</published>
<updated>2014-12-23T00:00:00+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven/">&lt;h1&gt;Installing third party jars in Maven&lt;/h1&gt;

&lt;p&gt;Some companies don&amp;#39;t put their jars in Maven official repositories, so when working in a local environment is useful to have this jars available as any other.&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
    mvn install:install-file -Dfile=JAR&lt;em&gt;FILE&lt;/em&gt;PATH -DgroupId=GROUP&lt;em&gt;ID -DartifactId=ARTIFACT&lt;/em&gt;ID -Dversion=VERSION  -Dpackaging=jar
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JAR&lt;em&gt;FILE&lt;/em&gt;PATH&lt;/strong&gt;: path to the jar file to install&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GROUP_ID&lt;/strong&gt;: Id to identify a group that will contains the jars released by the same provider (i.e. org.springframework)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ARTIFACT_ID&lt;/strong&gt;: Id to identify a single jar file (i.e. spring-core)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VERSION&lt;/strong&gt;: version of the specific jar (i.e. 1.2.0)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;to declare this new added jar in the pom.xml&lt;/p&gt;

&lt;p&gt;{% highlight xml %}
&lt;project&gt;
  ...
  &lt;dependencies&gt;
    ...
    &lt;dependency&gt;
      &lt;groupId&gt;GROUP&lt;em&gt;ID&lt;/groupId&gt;
      &lt;artifactId&gt;ARTIFACT&lt;/em&gt;ID&lt;/artifactId&gt;
      &lt;version&gt;VERSION&lt;/version&gt;
    &lt;/dependency&gt;
    ...
  &lt;/dependencies&gt;
  ...
&lt;/project&gt;
{% endhighlight %}&lt;/p&gt;
</content>
<category term="[&quot;maven&quot;, &quot;java&quot;, &quot;jar&quot;]" />
<summary>Installing third party jars in Maven</summary>
</entry>
<entry>
<title>Installing Hadoop in CentOS 7</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/11/installing-hadoop-centos-7/" rel="alternate" type="text/html" title="Installing Hadoop in CentOS 7" />
<published>2014-12-11T00:00:00+00:00</published>
<updated>2014-12-11T00:00:00+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/11/installing-hadoop-centos-7</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/11/installing-hadoop-centos-7/">&lt;h1&gt;Installing Hadoop in CentOS 7&lt;/h1&gt;

&lt;p&gt;In this article I&amp;#39;m going to focus in how to install Hadoop in CentOS 7. At the time of this writing there are two mantanined version of Hadoop that can be useful for different purposes, for these reasons we will install both. For Hadoop 1, we will use &lt;a href=&quot;http://mirror.ox.ac.uk/sites/rsync.apache.org/hadoop/common/stable1/hadoop-1.2.1.tar.gz&quot;&gt;hadoop-1.2.1&lt;/a&gt;, for Hadoop 2, &lt;a href=&quot;http://mirror.ox.ac.uk/sites/rsync.apache.org/hadoop/common/stable2/hadoop-2.6.0.tar.gz&quot;&gt;hadoop-2.6.0&lt;/a&gt;. For other versions check &lt;a href=&quot;http://www.apache.org/dyn/closer.cgi/hadoop/common/&quot;&gt;Hadoop Download Page&lt;/a&gt;. Also worth notice that the hostname of the machine where I&amp;#39;m doing the instalation is &lt;strong&gt;centos-vm&lt;/strong&gt; and I will use this name instead of &lt;strong&gt;localhost&lt;/strong&gt; because this will make possible to work with this installation remotely.&lt;/p&gt;

&lt;h2&gt;Installing Hadoop&lt;/h2&gt;

&lt;p&gt;There are different installation choices, I prefer to stay with the binaries because it gives me all the control about what is configured and where. Depending on the linux distribution choosen, using the RPMs could be another good choice. &lt;/p&gt;

&lt;p&gt;Because every version of Hadoop can introduce small changes this may not work in other versions, the best way to install it is following the instructions in the documentation included in the tar file.&lt;/p&gt;

&lt;p&gt;For each Hadoop version we will create a folder &lt;code&gt;/opt/apache-hadoop/hadoop-x.y.z&lt;/code&gt; and create a symbolic link &lt;code&gt;/opt/apache-hadoop/hadoopx&lt;/code&gt; that will make updates easier. In our case this translates into:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Hadoop 1&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Directory&lt;/em&gt;: &lt;code&gt;/opt/apache-hadoop/hadoop-1.2.1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Symbolic link&lt;/em&gt;: &lt;code&gt;/opt/apache-hadoop/hadoop1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hadoop 2&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Directory&lt;/em&gt;: &lt;code&gt;/opt/apache-hadoop/hadoop-2.6.0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Symbolic link&lt;/em&gt;: &lt;code&gt;/opt/apache-hadoop/hadoop2&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Before the installation we also need to create a user, a group and set the permissions:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;h1&gt;executed as super user&lt;/h1&gt;

&lt;p&gt;groupadd hadoop
useradd -g hadoop -c &amp;quot;Hadoop user&amp;quot; hadoop
mkdir /var/log/hadoop
chown -R hadoop:hadoop /var/log/hadoop
chmod -R u+xwr,g+xwr,o+xr /var/log/hadoop
mkdir /var/data/hadoop
chown -R hadoop:hadoop /var/data/hadoop
chmod -R u+xwr,g+xwr,o+xr /var/data/hadoop
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;After this we must set the new user to access to the host without authenticating. This can be checked with the command:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
ssh centos-vm
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;if you are asked for a password do the following:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
 # no parameters required (use default parameters)&lt;/p&gt;

&lt;p&gt;ssh-keygen &lt;/p&gt;

&lt;p&gt;# copy the generated key (would also work for a remote server)&lt;/p&gt;

&lt;p&gt;ssh-copy-id -i ~/.ssh/id_rsa.pub centos-vm&lt;/p&gt;

&lt;p&gt;# stop the ssh session (exit) and try&lt;/p&gt;

&lt;p&gt;ssh centos-vm
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;With this steps you should be able to access to the server without typing the password, making easier to use Hadoop&amp;#39;s start/stop scripts.&lt;/p&gt;

&lt;h2&gt;Hadoop 1&lt;/h2&gt;

&lt;h3&gt;Tar file structure&lt;/h3&gt;

&lt;p&gt;The uncompressed tar file has the following structure for Hadoop 1:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;hadoop-1.z.y/
├── bin
├── c++
├── conf
├── contrib
├── docs
├── ivy
├── lib
├── libexec
├── logs
├── sbin
├── share
├── src
└── webapps
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The documentation for this version is in the &lt;code&gt;docs&lt;/code&gt; directory. The details for the single node installation can be found in &lt;code&gt;docs/single_node_setup.html&lt;/code&gt;. Apart of the installation process, authentication/access problems are their solutions are also  described in this document.&lt;/p&gt;

&lt;h3&gt;Editing the configuration files for a Pseudo-distributed configuration&lt;/h3&gt;

&lt;p&gt;The first step is to set the &lt;code&gt;JAVA_HOME&lt;/code&gt; variable in &lt;code&gt;/opt/apache-hadoop/hadoop1/conf/hadoop-env.sh&lt;/code&gt;. Different Hadoop versions may need different Java SDK versions, this versions table can be found &lt;a href=&quot;http://wiki.apache.org/hadoop/HadoopJavaVersions&quot;&gt;here&lt;/a&gt;. I&amp;#39;m currently using Java 8 (1.8.0_25) and Hadoop is running without any issues. If at this point you don&amp;#39;t have Java in your system go to [Installing Java in CentOS 7][installingJavaCentOS].&lt;/p&gt;

&lt;p&gt;Supposing that the right version of java is installed in &lt;code&gt;/usr/java/latest&lt;/code&gt; the following command will change the configuration in the file &lt;code&gt;conf/hadoop-env.sh&lt;/code&gt;. Notice that this may not be required is you already have the right JDK installed and the JAVA&lt;em&gt;HOME variable defined (check using `echo &amp;quot;$JAVA&lt;/em&gt;HOME&amp;quot;`).&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
sed -i -e &amp;quot;s-^.&lt;em&gt;JAVA_HOME.&lt;/em&gt;-export JAVA_HOME=/usr/java/latest-g&amp;quot;  /opt/apache-hadoop/hadoop1/conf/hadoop-env.sh
{% endhighlight %}    &lt;/p&gt;

&lt;p&gt;In order to be a good linux citizen we will also configure the log path (&lt;code&gt;/var/log/hadoop&lt;/code&gt;):&lt;/p&gt;

&lt;p&gt;{% highlight bash %}&lt;br&gt;
sed -i -e &amp;quot;s-^.&lt;em&gt;HADOOP&lt;em&gt;LOG&lt;/em&gt;DIR.&lt;/em&gt;-export HADOOP&lt;em&gt;LOG&lt;/em&gt;DIR=/var/log/hadoop-g&amp;quot;  /opt/apache-hadoop/hadoop1/conf/hadoop-env.sh
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;For a &lt;em&gt;Pseudo-Distributed&lt;/em&gt; configuration these files must also be modified:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;conf/core-site.xml&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight xml %}
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.default.name&lt;/name&gt;
    &lt;value&gt;hdfs://centos-vm:9000&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
{% endhighlight %}  &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;conf/hdfs-site.xml&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the original Hadoop instructions, the properties below are not configured:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;dfs.name.dir&lt;/li&gt;
&lt;li&gt;dfs.data.dir&lt;/li&gt;
&lt;li&gt;dfs.client.buffer.dir&lt;/li&gt;
&lt;li&gt;mapred.local.dir&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Without this the required file structures will be created by default in the &lt;code&gt;/tmp/&lt;/code&gt; folder. This is not a good practice as some systems are configured to delete the content of this folder when the system restarts. To avoid this just configure any writable directory that will guaranty the persistence of the data. In the example below, we will assume this folder is &lt;code&gt;/var/data/hadoop&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;{% highlight xml %}
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;&lt;br&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.name.dir&lt;/name&gt;
    &lt;value&gt;/var/data/hadoop/dfs&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.data.dir&lt;/name&gt;
    &lt;value&gt;/var/data/hadoop/data&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.client.buffer.dir&lt;/name&gt;
    &lt;value&gt;/var/data/hadoop/buffer&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;mapred.local.dir&lt;/name&gt;
    &lt;value&gt;/var/data/hadoop/mapred&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
{% endhighlight %}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;conf/mapred-site.xml&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight xml %}&lt;/p&gt;

&lt;p&gt;&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;mapred.job.tracker&lt;/name&gt;
    &lt;value&gt;centos-vm:9001&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;&lt;/p&gt;

&lt;p&gt;{% endhighlight %}&lt;/p&gt;

&lt;h3&gt;Initializing Hadoop&lt;/h3&gt;

&lt;p&gt;Once all the configuration have been set, it is required to format the filesystem with the following command:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
cd /opt/apache-hadoop/hadoop1/bin
./hadoop namenode -format
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;The output should be similar to:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;14/12/20 01:35:12 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = centos-vm/127.0.0.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_25
************************************************************/
14/12/20 01:35:12 INFO util.GSet: Computing capacity for map BlocksMap
14/12/20 01:35:12 INFO util.GSet: VM type       = 64-bit
14/12/20 01:35:12 INFO util.GSet: 2.0% max memory = 932184064
14/12/20 01:35:12 INFO util.GSet: capacity      = 2^21 = 2097152 entries
14/12/20 01:35:12 INFO util.GSet: recommended=2097152, actual=2097152
14/12/20 01:35:13 INFO namenode.FSNamesystem: fsOwner=hadoop
14/12/20 01:35:13 INFO namenode.FSNamesystem: supergroup=supergroup
14/12/20 01:35:13 INFO namenode.FSNamesystem: isPermissionEnabled=true
14/12/20 01:35:13 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
14/12/20 01:35:13 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
14/12/20 01:35:13 INFO namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
14/12/20 01:35:13 INFO namenode.NameNode: Caching file names occuring more than 10 times 
14/12/20 01:35:13 INFO common.Storage: Image file /home/hadoop/data/1/dfs/current/fsimage of size 112 bytes saved in 0 seconds.
14/12/20 01:35:13 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/home/hadoop/data/1/dfs/current/edits
14/12/20 01:35:13 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/home/hadoop/data/1/dfs/current/edits
14/12/20 01:35:13 INFO common.Storage: Storage directory /home/hadoop/data/1/dfs has been successfully formatted.
14/12/20 01:35:13 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at centos-vm/127.0.0.1
************************************************************/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will using the folders structure configured previosly. When this step is done we are ready to start the system&lt;/p&gt;

&lt;h3&gt;starting/stopping the node&lt;/h3&gt;

&lt;p&gt;All the scrips to manage Hadoop can be also found in the &lt;strong&gt;bin&lt;/strong&gt; folder (&lt;code&gt;/opt/apache-hadoop/hadoop1/bin&lt;/code&gt;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start the hadoop daemons:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight bash %}
start-all.sh
{% endhighlight %}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To stop the node use:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight bash %}
stop-all.sh
{% endhighlight %}      &lt;/p&gt;

&lt;p&gt;When the service is started, Hadoop offers web interfaces to know the status of the system:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;NameNode - http://centos-vm:50070/
DataNode - http://centos-vm:50075/
JobTracker - http://centos-vm:50030/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Make Hadoop web interface available for remote access&lt;/h3&gt;

&lt;p&gt;{% highlight bash %}
firewall-cmd --permanent --zone=public --add-port=50070/tcp
firewall-cmd --permanent --zone=public --add-port=50075/tcp
firewall-cmd --permanent --zone=public --add-port=50030/tcp
firewall-cmd --reload
{% endhighlight %}&lt;/p&gt;

&lt;h2&gt;Hadoop 2&lt;/h2&gt;

&lt;p&gt;For Hadoop 2 some details are slightly different so we will go through them, Also the introduction of the new MapReduce engine, &lt;a href=&quot;http://en.wikipedia.org/wiki/Apache_Hadoop&quot;&gt;YARN&lt;/a&gt;, will require some aditional configuration.&lt;/p&gt;

&lt;h3&gt;Tar file structure&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;hadoop-2.6.0/
├── bin
├── etc
├── include
├── lib
├── libexec
├── sbin
└── share
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For this version the documentation is in &lt;code&gt;share/doc&lt;/code&gt; and the single node installation in &lt;code&gt;share/doc/hadoop/hadoop-project-dist/hadoop-common/SingleCluster.html&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Editing the configuration files for a Pseudo-distributed configuration&lt;/h3&gt;

&lt;p&gt;In the same way as we did for Hadoop 1, we may need to redefine JAVA_HOME, the &lt;code&gt;hadoop-env.sh&lt;/code&gt; file has also been moved to another directory: &lt;code&gt;/opt/apache-hadoop/hadoop2/etc/hadoop/hadoop-env.sh&lt;/code&gt;. Because of the number of environment variables required to have a proper configuration I opted for defining then as a script in the &lt;code&gt;/etc/profile.d&lt;/code&gt; directory&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/etc/profile.d/hadoop.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight bash %}
export HADOOP&lt;em&gt;HOME=/opt/apache-hadoop/default
export HADOOP=$HADOOP&lt;/em&gt;HOME/bin
export PATH=$HADOOP:$PATH&lt;/p&gt;

&lt;p&gt;export HADOOP&lt;em&gt;PREFIX=$HADOOP&lt;/em&gt;HOME
export HADOOP&lt;em&gt;CONF&lt;/em&gt;DIR=$HADOOP&lt;em&gt;PREFIX/etc/hadoop
export HADOOP&lt;/em&gt;YARN&lt;em&gt;HOME=$HADOOP&lt;/em&gt;HOME&lt;/p&gt;

&lt;p&gt;export NN&lt;em&gt;DATA&lt;/em&gt;DIR=/var/data/hadoop/hdfs/nn
export SNN&lt;em&gt;DATA&lt;/em&gt;DIR=/var/data/hadoop/hdfs/snn
export DN&lt;em&gt;DATA&lt;/em&gt;DIR=/var/data/hadoop/hdfs/dn
export YARN&lt;em&gt;LOG&lt;/em&gt;DIR=/var/log/hadoop/yarn
export HADOOP&lt;em&gt;LOG&lt;/em&gt;DIR=/var/log/hadoop/hdfs
export HADOOP&lt;em&gt;MAPRED&lt;/em&gt;LOG&lt;em&gt;DIR=/var/log/hadoop/mapred
export YARN&lt;/em&gt;PID&lt;em&gt;DIR=/var/run/hadoop/yarn
export HADOOP&lt;/em&gt;PID&lt;em&gt;DIR=/var/run/hadoop/hdfs
export HADOOP&lt;/em&gt;MAPRED&lt;em&gt;PID&lt;/em&gt;DIR=/var/run/hadoop/mapred
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;this can also be defined on the &lt;code&gt;.bashrc&lt;/code&gt; file in the hadoop user home directory.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;etc/hadoop/core-site.xml&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight xml %}
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://centos-vm:9000&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
{% endhighlight %}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;etc/hadoop/hdfs-site.xml&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notice that in this version the file paths must be given as URIs.&lt;/p&gt;

&lt;p&gt;{% highlight xml %}
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.name.dir&lt;/name&gt;
    &lt;value&gt;file:///var/data/hadoop/dfs&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.data.dir&lt;/name&gt;
    &lt;value&gt;file:///var/data/hadoop/dfs/data&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.client.buffer.dir&lt;/name&gt;
    &lt;value&gt;file:///var/data/hadoop/dfs/buffer&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;mapred.local.dir&lt;/name&gt;
    &lt;value&gt;file://var/data/hadoop/mapred&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
{% endhighlight %}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;etc/hadoop/mapred-site.xml&lt;/strong&gt; (must be created or copied from &lt;em&gt;mapred-site.xml.template&lt;/em&gt;):&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight xml %}
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
{% endhighlight %}  &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;etc/hadoop/yarn-site.xml&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight xml %}
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
{% endhighlight %}&lt;/p&gt;

&lt;h3&gt;Initializing Hadoop&lt;/h3&gt;

&lt;p&gt;The command to format the filesystem has been changed in Hadoop2:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
cd /opt/apache-hadoop/hadoop2/bin
./hdfs namenode -format
{% endhighlight %}    &lt;/p&gt;

&lt;h3&gt;starting/stopping the node&lt;/h3&gt;

&lt;p&gt;The directory where the scripts to start/stop that system has also change, being located now in the folder &lt;strong&gt;sbin&lt;/strong&gt;  (&lt;code&gt;/opt/apache-hadoop/hadoop2/sbin&lt;/code&gt;). Notice that for this version the &lt;code&gt;start-all.sh&lt;/code&gt; and &lt;code&gt;stop-all.sh&lt;/code&gt; have been deprecated. We will also need certain environment variables declared to make the configuration work, because this installation is only for development purposes, we will declare the environment variables in the startup script&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start Hadoop2:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;p&gt;mkdir -p /var/run/hadoop
chown -R hadoop:hadoop /var/run/hadoop
echo &amp;quot;Starting Hadoop2 NameNode and DataNode&amp;quot;
su - hadoop -c &amp;#39;/opt/apache-hadoop/hadoop2/sbin/start-dfs.sh&amp;#39;
echo &amp;quot;Starting Hadoop2 YARN&amp;quot;
su - hadoop -c &amp;#39;/opt/apache-hadoop/hadoop2/sbin/start-yarn.sh&amp;#39;
echo &amp;quot;Starting Job History server&amp;quot;
su - hadoop -c &amp;#39;/opt/apache-hadoop/hadoop2/sbin/mr-jobhistory-daemon.sh start historyserver&amp;#39;&lt;/p&gt;

&lt;p&gt;{% endhighlight %}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Stop Hadoop2:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;p&gt;echo &amp;quot;Stopping Hadoop2 NameNode and DataNode&amp;quot;
su - hadoop -c &amp;#39;/opt/apache-hadoop/hadoop2/sbin/stop-dfs.sh&amp;#39;
echo &amp;quot;Stopping Hadoop2 YARN&amp;quot;
su - hadoop -c &amp;#39;/opt/apache-hadoop/hadoop2/sbin/stop-yarn.sh&amp;#39;
echo &amp;quot;Stopping Job History Server&amp;quot;
su - hadoop -c &amp;#39;/opt/apache-hadoop/hadoop2/sbin/mr-jobhistory-daemon.sh stop historyserver&amp;#39;
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Once the service is started, Hadoop offers web interfaces to know the status of the system:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;NameNode - http://centos-vm:50070/
DataNode - http://centos-vm:50075/
Cluster Metrics - http://centos-vm:8088/
Job History - http://centos-vm:19888/
NodeManager Information - http://centos-vm:8042/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Make Hadoop web interface available for remote access&lt;/h3&gt;

&lt;p&gt;{% highlight bash %}
firewall-cmd --permanent --zone=public --add-port=50070/tcp
firewall-cmd --permanent --zone=public --add-port=50075/tcp
firewall-cmd --permanent --zone=public --add-port=8088/tcp
firewall-cmd --permanent --zone=public --add-port=19888/tcp
firewall-cmd --permanent --zone=public --add-port=8042/tcp
firewall-cmd --reload
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Updated 2015-03-16&lt;/em&gt;: Configuration improved to use linux standards. Start / Stop script improved. New Ports to open added to the list.&lt;/p&gt;

&lt;p&gt;[installingJavaCentOS]: {{site.baseurl}}{% post_url 2014-10-14-installing-java-centos-7 %}&lt;/p&gt;
</content>
<summary>Installing Hadoop in CentOS 7</summary>
</entry>
<entry>
<title>Installing MongoDB in CentOS 7</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/10/installing-mongodb-centos-7/" rel="alternate" type="text/html" title="Installing MongoDB in CentOS 7" />
<published>2014-12-10T00:00:00+00:00</published>
<updated>2014-12-10T00:00:00+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/10/installing-mongodb-centos-7</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/10/installing-mongodb-centos-7/">&lt;h1&gt;Installing MongoDB in CentOS 7&lt;/h1&gt;

&lt;h1&gt;Adding MongoDB repositories to yum&lt;/h1&gt;

&lt;p&gt;Following the steps specified in the [MongoDB installation guide][], we need to add mongo to the yum repository adding to &lt;code&gt;/etc/yum.repos.d/mongodb.repo&lt;/code&gt; the following:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;[mongodb]
name=MongoDB Repository
baseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/
gpgcheck=0
enabled=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As &lt;a href=&quot;TODO&quot;&gt;super user&lt;/a&gt; this file can be created using the command showed below:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
printf &amp;quot;[mongodb]\nname=MongoDB Repository\nbaseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/\ngpgcheck=0\nenabled=1\n&amp;quot; &amp;gt; /etc/yum.repos.d/mongodb.repo
{% endhighlight %}    &lt;/p&gt;

&lt;h1&gt;Installing MongoDB with yum&lt;/h1&gt;

&lt;p&gt;Once the file have been created we can install MongoDB using yum:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;h1&gt;run as super user, su/sudo&lt;/h1&gt;

&lt;p&gt;yum install -y mongodb-org
{% endhighlight %}&lt;/p&gt;

&lt;h1&gt;Configuring MongoDB&lt;/h1&gt;

&lt;p&gt;By default, MongoDB configuration is stored in &lt;code&gt;/etc/mongodb.conf&lt;/code&gt; there is not need to change anything to make it work. In the case external connections are required, the value &lt;code&gt;bind_ip=127.0.0.1&lt;/code&gt; must be commented out. This can be done using:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;h1&gt;run as super user, su/sudo&lt;/h1&gt;

&lt;p&gt;sed -i -e s/bind&lt;em&gt;ip=127.0.0.1/#bind&lt;/em&gt;ip=127.0.0.1/g /etc/mongod.conf
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;By default MongoDB is runining on the port 21017, so as part of allowing external access, this port must be opened in the firewall.&lt;/p&gt;

&lt;h1&gt;Opening MongoDB ports in CentOS 7&lt;/h1&gt;

&lt;p&gt;{% highlight bash %}
firewall-cmd --permanent --zone=public --add-port=27017/tcp
firewall-cmd --reload
{% endhighlight %}&lt;/p&gt;

&lt;h1&gt;Managing MongoDB service&lt;/h1&gt;

&lt;p&gt;{% highlight bash %}
sudo service mongod start
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;[openingPortsCentos7]: {{site.baseurl}}{% post_url 2014-12-01-opening-ports-in-centos-7 %}&lt;/p&gt;
</content>
<summary>Installing MongoDB in CentOS 7</summary>
</entry>
<entry>
<title>Configuring a Maven project hosted in Bitbucket in Jenkins</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/05/integrating-bitbucket-repo-jenkins/" rel="alternate" type="text/html" title="Configuring a Maven project hosted in Bitbucket in Jenkins" />
<published>2014-12-05T00:00:00+00:00</published>
<updated>2014-12-05T00:00:00+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/05/integrating-bitbucket-repo-jenkins</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/05/integrating-bitbucket-repo-jenkins/">&lt;h1&gt;Configuring a Maven project hosted in Bitbucket&lt;/h1&gt;

&lt;p&gt;If you don&amp;#39;t have Jenkins installed in  your system go to [How to install Jenkins][jenkinsInstall]&lt;/p&gt;

&lt;h2&gt;Installing Bitbucket plugins&lt;/h2&gt;

&lt;p&gt;Manage Jenkins -&amp;gt; Manage Plugins&lt;/p&gt;

&lt;p&gt;Go to the &lt;em&gt;Available&lt;/em&gt; tab and filter by &amp;quot;Bitbucket&amp;quot;, you will get the entries listed below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bitbucket OAuth Plugin&lt;/li&gt;
&lt;li&gt;Bitbucket Plugin&lt;/li&gt;
&lt;li&gt;Bitbucket Pullrequest Builder Plugin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Not all this plugins are required to build from Bitbucket&lt;/p&gt;

&lt;h2&gt;Creating new Item for a Maven project hosted in Bitbucket&lt;/h2&gt;

&lt;p&gt;New Item -&amp;gt; Maven Project&lt;/p&gt;

&lt;p&gt;Maven project name:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Source Code Management

&lt;ul&gt;
&lt;li&gt;Repository URL&lt;/li&gt;
&lt;li&gt;Credentials&lt;/li&gt;
&lt;li&gt;Branches to build : */master (or any other specified)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Build Triggers

&lt;ul&gt;
&lt;li&gt;Build whenever a SNAPSHOT dependency is built&lt;/li&gt;
&lt;li&gt;Build when a change is pushed to BitBucket&lt;/li&gt;
&lt;li&gt;Build periodically: @midnight&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Build

&lt;ul&gt;
&lt;li&gt;Root POM: pom.xml&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Build Settings:

&lt;ul&gt;
&lt;li&gt;E-mail notification: setting the recipient and send emails for different cases, the most common one is for failed builds, so you can know as soon as a build fails.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[jenkinsInstall]: {{site.baseurl}}{% post_url 2014-12-03-installing-jenkins-centos-7 %}&lt;/p&gt;
</content>
<summary>Configuring a Maven project hosted in Bitbucket</summary>
</entry>
<entry>
<title>Installing and configuring Jenkins in CentOS 7</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/03/installing-jenkins-centos-7/" rel="alternate" type="text/html" title="Installing and configuring Jenkins in CentOS 7" />
<published>2014-12-03T00:00:00+00:00</published>
<updated>2014-12-03T00:00:00+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/03/installing-jenkins-centos-7</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/2014/12/03/installing-jenkins-centos-7/">&lt;h1&gt;Installing Jenkins&lt;/h1&gt;

&lt;p&gt;The easies way to install jenkins is following the instructions in their &lt;a href=&quot;https://wiki.jenkins-ci.org/display/JENKINS/Installing+Jenkins+on+RedHat+distributions&quot;&gt;official page&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo
sudo rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.key
sudo yum install jenkins
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Jenkins require java installed, to do so check [Installing java in CentOS][InstallingJavaCentOS]&lt;/p&gt;

&lt;h2&gt;Configuring Jenkins&lt;/h2&gt;

&lt;h2&gt;Changing the default port when Jenkins is installed as a service&lt;/h2&gt;

&lt;p&gt;The script that manages Jenkins on the system is located in &lt;code&gt;/etc/init.d/jenkins&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So to change the default port, 8080, the easiest way is to replace the value of the variable &lt;code&gt;HTTP_PORT&lt;/code&gt; in the file &lt;code&gt;/etc/sysconfig/jenkins&lt;/code&gt;. This can be done using the following command as super user, where NEW_PORT is the value of the port you want to asign&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
sed -i s/JENKINS&lt;em&gt;PORT=\&amp;quot;8080\&amp;quot;/JENKINS&lt;/em&gt;PORT=\&amp;quot;{NEW_PORT}\&amp;quot;/g /etc/sysconfig/jenkins
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Then you just need to restart the service&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
/etc/init.d/jenkins restart #service jenkins restart #will also works
{% endhighlight %}&lt;/p&gt;

&lt;h2&gt;Setting jenkins to start when the server starts&lt;/h2&gt;

&lt;p&gt;{% highlight bash %}
chkconfig jenkins on
{% endhighlight %}&lt;/p&gt;

&lt;h2&gt;Opening Jenkins ports&lt;/h2&gt;

&lt;p&gt;CentOS 7 has a new firewall application, for previous versions the service is called &lt;em&gt;iptables&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
firewall-cmd --permanent --zone=public --add-port={NEW_PORT}/tcp
firewall-cmd --reload
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;[InstallingJavaCentOS]: {{site.baseurl}}{% post_url 2014-10-14-installing-java-centos-7 %}&lt;/p&gt;
</content>
<summary>Installing Jenkins</summary>
</entry>
<entry>
<title>Opening ports in CentOS 7</title>
<link href="http://joseestudillo.comhttp://blog.joseestudillo.com/linux/centos/2014/12/01/opening-ports-in-centos-7/" rel="alternate" type="text/html" title="Opening ports in CentOS 7" />
<published>2014-12-01T00:00:00+00:00</published>
<updated>2014-12-01T00:00:00+00:00</updated>
<id>http://joseestudillo.comhttp://blog.joseestudillo.com/linux/centos/2014/12/01/opening-ports-in-centos-7</id>
<content type="html" xml:base="http://joseestudillo.comhttp://blog.joseestudillo.com/linux/centos/2014/12/01/opening-ports-in-centos-7/">&lt;h1&gt;Opening ports in CentOS 7&lt;/h1&gt;

&lt;p&gt;CentOS 7.0 doesn&amp;#39;t use iptables anymore to handle the ports, and it has been replaced by firewall-cmd.&lt;/p&gt;

&lt;p&gt;In the following example, I show how to permanently open the port XXXX:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;h1&gt;run as super user, su/sudo&lt;/h1&gt;

&lt;p&gt;firewall-cmd --permanent --zone=public --add-port=XXXX/tcp
firewall-cmd --reload
{% endhighlight %}&lt;/p&gt;
</content>
<summary>Opening ports in CentOS 7</summary>
</entry>
</feed>
