<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="{"en"=>{"description"=>"Jose Estudillo's Blog. Software engineering and technology blog."}, "es"=>{"description"=>"Blog de Jose Estudillo"}}"><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://joseestudillo.com/https://blog.joseestudillo.com/feed.xml" rel="self" type="application/atom+xml" /><link href="http://joseestudillo.com/https://blog.joseestudillo.com/" rel="alternate" type="text/html" hreflang="{"en"=>{"description"=>"Jose Estudillo's Blog. Software engineering and technology blog."}, "es"=>{"description"=>"Blog de Jose Estudillo"}}" /><updated>2022-04-19T21:22:24+01:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/feed.xml</id><title type="html">Jose Estudillo’s Blog</title><subtitle>Jose Estudillo&apos;s Blog. Software engineering and technology blog.</subtitle><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><entry><title type="html">Creating a scalable kafka cluster with docker</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/2018/01/15/creating-scalable-kafka-cluster-with-docker/" rel="alternate" type="text/html" title="Creating a scalable kafka cluster with docker" /><published>2018-01-15T00:00:00+00:00</published><updated>2018-01-15T00:00:00+00:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/2018/01/15/creating-scalable-kafka-cluster-with-docker</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/2018/01/15/creating-scalable-kafka-cluster-with-docker/"><![CDATA[<h1 id="creating-a-scalable-kafka-cluster-with-docker">Creating a scalable kafka cluster with docker</h1>

<p>The auto broker id features of <a href="https://kafka.apache.org/">Kafka</a> combined with <a href="https://docs.docker.com/compose/">Docker compose</a> scaling capabilities allow to create a cluster with N number of nodes with very little effort.</p>

<h2 id="the-kafka-docker-image">The Kafka docker image</h2>

<p>We will need an image that can start a broker and use zookeeper to form the cluster.</p>

<ul>
  <li>Dockerfile for the kafka brokers:</li>
</ul>

<div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> centos:7</span>
<span class="k">MAINTAINER</span><span class="s"> jose@estudillo.me</span>

<span class="k">ENV</span><span class="s"> K_SRC=http://apache.mirror.anlx.net/kafka/1.0.1/kafka_2.11-1.0.1.tgz</span>

<span class="k">RUN </span>yum <span class="nb">install</span> <span class="nt">-y</span> wget java-1.8.0-openjdk <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /tmp <span class="o">&amp;&amp;</span> wget <span class="nt">-q</span> <span class="nv">$K_SRC</span> <span class="se">\ </span>
    &amp;&amp; export K_TAR=/tmp/$(ls kafka* | head -1) \
    &amp;&amp; mkdir -p /opt/apache/kafka/ &amp;&amp; tar -zxf $K_TAR -C /opt/apache/kafka/ \
    &amp;&amp; cd /opt/apache/kafka &amp;&amp; ln -s $(ls) current \
    &amp;&amp; rm -rf $K_TAR

<span class="k">ENV</span><span class="s"> KAFKA_HOME /opt/apache/kafka/current</span>
<span class="k">ENV</span><span class="s"> PATH $PATH:$KAFKA_HOME/bin</span>

<span class="k">ADD</span><span class="s"> resources /home/kafka</span>

<span class="k">RUN </span>groupadd <span class="nt">-r</span> kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> useradd <span class="nt">-r</span> <span class="nt">-g</span> kafka kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> /home/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">chown</span> <span class="nt">-R</span> kafka:kafka /home/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">chmod</span> <span class="nt">-R</span> +x /home/kafka/bin <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> /var/log/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">chown</span> <span class="nt">-R</span> kafka:kafka /var/log/kafka

<span class="k">USER</span><span class="s"> kafka</span>

<span class="k">CMD</span><span class="s"> /home/kafka/bin/run.sh</span>
</code></pre></div></div>

<p>Where <code class="language-plaintext highlighter-rouge">/home/kafka/bin/run.sh</code> allow to define the configuration of the broker dynamically and start it:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">resources/bin/run.sh</code>:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /home/kafka/broker.properties
broker.id.generation.enable = true
port=9092
log.dir=/var/log/kafka
zookeeper.connect=</span><span class="k">${</span><span class="nv">KAFKA_ZOOKEEPER_HOST</span>:<span class="p">=zookeeper</span>:2181<span class="k">}</span><span class="sh">
host.name=</span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="sh">
advertised.host.name=</span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="sh">
advertised.host.port=9092
</span><span class="no">EOF

</span>kafka-server-start.sh /home/kafka/broker.properties
</code></pre></div></div>

<p>Kafka auto broker id generation (<code class="language-plaintext highlighter-rouge">broker.id.generation.enable = true</code>) makes scaling the cluster easier (in older versions the id had to be setup for each broker), this will use zookeeper to keep all the brokers that join the cluster with unique ids.</p>

<p>Notice that this or any other file must be located in the <code class="language-plaintext highlighter-rouge">resources</code> (at the same level of the <code class="language-plaintext highlighter-rouge">Dockerfile</code>), as in the image definition map this directory to <code class="language-plaintext highlighter-rouge">/home/kafka</code> (<code class="language-plaintext highlighter-rouge">ADD resources /home/kafka</code>).</p>

<p>Before running docker-compose we will need images in the docker local repo, the images can be generated using:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">--tag</span><span class="o">=</span><span class="s2">"joseestudillo/kafka:0.0.1"</span> <span class="nb">.</span>
docker tag joseestudillo/kafka:0.0.1 joseestudillo/kafka:latest
</code></pre></div></div>

<h2 id="scaling-with-docker-compose">Scaling with docker-compose</h2>

<p>In the docker compose definition we will only need to entries, one for the zookeeper server, that is not available for simplicity, and one for the kafka brokers that will use <code class="language-plaintext highlighter-rouge">KAFKA_ZOOKEEPER_HOST</code> to join the kafka cluster.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">2.1'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">zookeeper</span><span class="pi">:</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">zookeeper</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">zookeeper:latest</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">ZOO_MY_ID</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">always</span>
    <span class="na">healthcheck</span><span class="pi">:</span>
        <span class="na">test</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">CMD"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">zkServer.sh"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">status"</span><span class="pi">]</span>

  <span class="na">kafka_broker</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">joseestudillo/kafka:latest</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">KAFKA_ZOOKEEPER_HOST</span><span class="pi">:</span> <span class="s">zookeeper:2181/kafka-docker-compose</span>
      <span class="na">KAFKA_LOG_DIR</span><span class="pi">:</span> <span class="s">/var/log/kafka</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">/var/run/docker.sock:/var/run/docker.sock</span>
    <span class="na">depends_on</span><span class="pi">:</span>
      <span class="na">zookeeper</span><span class="pi">:</span>
        <span class="na">condition</span><span class="pi">:</span> <span class="s">service_healthy</span>
</code></pre></div></div>

<p>With this file defined, we just need to call <code class="language-plaintext highlighter-rouge">docker-compose up --scale kafka_broker=5</code> and it will start a kafka cluster with 5 brokers.</p>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><summary type="html"><![CDATA[Creating a scalable kafka cluster with docker]]></summary></entry><entry><title type="html">Extending Vagrant Boxes: Creating your own Vagrant boxes</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/2017/09/06/extending-vagrant-boxes/" rel="alternate" type="text/html" title="Extending Vagrant Boxes: Creating your own Vagrant boxes" /><published>2017-09-06T00:00:00+01:00</published><updated>2017-09-06T00:00:00+01:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/2017/09/06/extending-vagrant-boxes</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/2017/09/06/extending-vagrant-boxes/"><![CDATA[<h1 id="extending-vagrant-boxes">Extending Vagrant Boxes</h1>

<p>It’s a common case in <a href="https://www.vagrantup.com/">Vagrant</a> wanting to have base boxes that contain certain package or specific software to be able to create different type of clusters with little effort.</p>

<p>The most common case when using <a href="https://www.vagrantup.com/">Vagrant</a>  is to specify a script that will download the software and prepare the box on startup, but this is quite inefficient, specially if we are downloading a lot of information from the internet that could be common for many of the instances.</p>

<h1 id="defining-your-own-boxed-extending-from-a-base-image">Defining your own boxed extending from a base image</h1>

<p>For the examples I will use <a href="https://www.centos.org/">CentOS</a> (<code class="language-plaintext highlighter-rouge">centos/7</code>) as a base image as it is one of the most common server OS.</p>

<h2 id="defining-a-box-using-inline-script">Defining a box using Inline script</h2>

<p>Using the inline script capabilities is the fastest way to define what our custom box will require:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Vagrantfile</code>:
    <pre><code class="language-Vagrantfile">Vagrant.configure("2") do |config|
config.vm.box = "centos/7"
config.ssh.insert_key = false
config.vm.provision "shell", inline: &lt;&lt;-SHELL
  yum update -y
  yum install -y git
SHELL  
end
</code></pre>
  </li>
</ul>

<h2 id="defining-a-box-using-external-script">Defining a box Using external script</h2>

<p>For the cases where we need to do more complex installation, it is cleaner to create a external script and point to it from the <code class="language-plaintext highlighter-rouge">Vagrantfile</code>.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Vagrantfile</code>:</li>
</ul>

<pre><code class="language-Vagrantfile">Vagrant.configure("2") do |config|
  config.vm.box = "centos/7"
  config.ssh.insert_key = false
  config.vm.provision :shell, path: ".vagrant/scripts/init.sh"  
end
</code></pre>

<p>An example of init script could be:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">.vagrant/scripts/init.sh</code>:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/usr/bin/env bash
yum update -y
yum install -y git
</code></pre></div>    </div>
  </li>
</ul>

<p>The location of the script can be anywhere in the directory where the <code class="language-plaintext highlighter-rouge">VagrantFile</code> is, but I like to keep the init scripts under <code class="language-plaintext highlighter-rouge">.vagrant</code> directory, so they are used the first time the Virtual machine is started, but never copied into it (<a href="https://www.vagrantup.com/">Vagrant</a> ignored the context of this directory by default).</p>

<h1 id="installing-the-extend-box">Installing the extend box</h1>

<p>I have noticed that the generated boxes only work correctly when the vguest plugin installed, so I advice to install it before running any of the scripts below. This can be done running <code class="language-plaintext highlighter-rouge">vagrant plugin install vagrant-vbguest</code>.</p>

<p>To install the box we will create a vagrant virtual machine that will download and install all the specified software, turn it off and package it into a box to install it in the vagrant boxes repo.</p>

<p>the script below can do all this steps in one go and will clean the generated files after.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">BOX_ID</span><span class="o">=</span><span class="s2">"&lt;your box id&gt;"</span>
vagrant destroy <span class="nt">-f</span>
<span class="nb">set</span> <span class="nt">-e</span>
vagrant up <span class="c"># Start the box and run any defined scripts</span>
vagrant package <span class="nt">--output</span> <span class="k">${</span><span class="nv">BOX_ID</span><span class="k">}</span>.box <span class="c"># Store the virtual machine with all the software installed into a box file.</span>
vagrant box add <span class="nt">--force</span> <span class="k">${</span><span class="nv">BOX_ID</span><span class="k">}</span> <span class="k">${</span><span class="nv">BOX_ID</span><span class="k">}</span>.box <span class="c"># Add the box to the vagrant repo using the given id.</span>
vagrant destroy <span class="nt">-f</span> <span class="c"># Stop the vagrant instance</span>
<span class="nb">rm</span> <span class="k">${</span><span class="nv">BOX_ID</span><span class="k">}</span>.box <span class="c"># Remove the file </span>
</code></pre></div></div>

<p>Once the the previous steps are completed, you can use your newly created box as base assigning the id (<code class="language-plaintext highlighter-rouge">BOX_ID</code> value) to <code class="language-plaintext highlighter-rouge">config.vm.box</code>:</p>

<pre><code class="language-Vagrantfile">Vagrant.configure("2") do |config|
  config.vm.box = "&lt;box id&gt;"
  ...  
end
</code></pre>

<p>In the next article I will show how to configure these boxes to create clusters.</p>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><summary type="html"><![CDATA[Extending Vagrant Boxes]]></summary></entry><entry><title type="html">Creating a kafka cluster with docker</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/2017/08/27/creating-kafka-cluster-with-docker/" rel="alternate" type="text/html" title="Creating a kafka cluster with docker" /><published>2017-08-27T00:00:00+01:00</published><updated>2017-08-27T00:00:00+01:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/2017/08/27/creating-kafka-cluster-with-docker</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/2017/08/27/creating-kafka-cluster-with-docker/"><![CDATA[<p><a href="https://blog.joseestudillo.com/https://blog.joseestudillo.com/2018/01/15/creating-scalable-kafka-cluster-with-docker/">Updated version of this article</a></p>

<h1 id="creating-a-kafka-cluster-with-docker">Creating a kafka cluster with docker</h1>

<p>A local <a href="https://kafka.apache.org/">Kafka</a> cluster will help to develop producer and consumers, allowing to test different scenarios specially when it comes to HA. In this article I’ll show how to create a kafka cluster using <a href="https://www.docker.com/">docker</a> and <a href="https://docs.docker.com/compose/">docker-compose</a>.</p>

<h2 id="defining-kafka-image-dockerfile">Defining kafka image: Dockerfile</h2>

<p>For the creation of the <a href="https://www.docker.com/">docker</a> image we will use the version <a href="http://www-eu.apache.org/dist/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz">0.11.0.0</a> as specified in the code below in the environment var <code class="language-plaintext highlighter-rouge">KAFKA_BIN</code>.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Dockerfile</code>:</li>
</ul>

<div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> centos:7</span>
<span class="k">MAINTAINER</span><span class="s"> jose@estudillo.me</span>

<span class="k">ENV</span><span class="s"> KAFKA_BIN=http://www-eu.apache.org/dist/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz</span>

<span class="k">RUN </span>yum <span class="nb">install</span> <span class="nt">-y</span> wget java-1.8.0-openjdk <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /tmp <span class="o">&amp;&amp;</span> wget <span class="nt">-q</span> <span class="nv">$KAFKA_BIN</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">export </span><span class="nv">K_TAR</span><span class="o">=</span>/tmp/<span class="si">$(</span><span class="nb">ls </span>kafka<span class="k">*</span> | <span class="nb">head</span> <span class="nt">-1</span><span class="si">)</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> /opt/apache/kafka/ <span class="o">&amp;&amp;</span> <span class="nb">tar</span> <span class="nt">-zxf</span> <span class="nv">$K_TAR</span> <span class="nt">-C</span> /opt/apache/kafka/ <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /opt/apache/kafka <span class="o">&amp;&amp;</span> <span class="nb">ln</span> <span class="nt">-s</span> <span class="si">$(</span><span class="nb">ls</span><span class="si">)</span> current <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> <span class="nv">$K_TAR</span>

<span class="k">ENV</span><span class="s"> KAFKA_HOME /opt/apache/kafka/current</span>
<span class="k">ENV</span><span class="s"> PATH $PATH:$KAFKA_HOME/bin</span>

<span class="k">ADD</span><span class="s"> resources /home/kafka</span>

<span class="k">RUN </span>groupadd <span class="nt">-r</span> kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> useradd <span class="nt">-r</span> <span class="nt">-g</span> kafka kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> /home/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">chown</span> <span class="nt">-R</span> kafka:kafka /home/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">chmod</span> <span class="nt">-R</span> +x /home/kafka/scripts <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> /var/log/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">chown</span> <span class="nt">-R</span> kafka:kafka /var/log/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> /etc/kafka <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">chown</span> <span class="nt">-R</span> kafka:kafka /etc/kafka

<span class="k">USER</span><span class="s"> kafka</span>

<span class="k">CMD</span><span class="s"> /home/kafka/scripts/run.sh</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">Dockerimage</code> will download the <a href="https://kafka.apache.org/">Kafka</a> binaries and place then into <code class="language-plaintext highlighter-rouge">/opt/apache/kafka</code> and link the current version to <code class="language-plaintext highlighter-rouge">/opt/apache/kafka/current</code>, after that it add it into the <code class="language-plaintext highlighter-rouge">PATH</code> and create the required directories that need to be owned by the <code class="language-plaintext highlighter-rouge">kafka</code> user.</p>

<p>In order to configure and start the broker properly, <code class="language-plaintext highlighter-rouge">CMD</code> needs to call a bash script that must be added to the image <code class="language-plaintext highlighter-rouge">ADD resources /home/kafka</code>, putting all the content from the local directory <code class="language-plaintext highlighter-rouge">resources</code> in the image directory <code class="language-plaintext highlighter-rouge">/home/kafka</code>.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">resources/scripts/run.sh</code></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/kafka/broker.properties
broker.id=</span><span class="si">$(</span><span class="nb">hostname</span> | <span class="nb">sed</span> <span class="s2">"s/[^0-9]*//g"</span><span class="si">)</span><span class="sh">
port=9092
log.dir=/var/log/kafka
zookeeper.connect=</span><span class="k">${</span><span class="nv">KAFKA_ZOOKEEPER_HOST</span>:<span class="p">=zookeeper</span>:2181<span class="k">}</span><span class="sh">
host.name=</span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="sh">
advertised.host.name=</span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="sh">
advertised.host.port=9092
</span><span class="no">EOF

</span>kafka-server-start.sh /etc/kafka/broker.properties
</code></pre></div></div>

<p>For this to work we require:</p>

<ul>
  <li>Every container created from this image must contain a number in the hostname, so it can be used as <code class="language-plaintext highlighter-rouge">broker.id</code>.</li>
  <li>Kafka requires <a href="https://zookeeper.apache.org/">Zookeeper</a> to be able to work, the script will assume that the hostname for this is <code class="language-plaintext highlighter-rouge">zookeeper</code>, but this value can be also specified in the env var <code class="language-plaintext highlighter-rouge">KAFKA_ZOOKEEPER_HOST</code> (i.c. `zoo1:2181,zoo2:2181,zoo3:2181)</li>
</ul>

<h2 id="creating-the-kafka-image-from-the-dockerfile">Creating the kafka image from the Dockerfile</h2>

<p>In this example I use my own namespace (<code class="language-plaintext highlighter-rouge">joseestudillo</code>) but this is not required and can be omitted. I also add the version <code class="language-plaintext highlighter-rouge">latest</code> to follow docker image naming standards.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">--tag</span><span class="o">=</span><span class="s2">"joseestudillo/kafka:0.0.1"</span> <span class="nb">.</span>
docker tag joseestudillo/kafka:0.0.1 joseestudillo/kafka:latest
</code></pre></div></div>

<h2 id="creating-the-cluster-docker-compose">Creating the cluster: docker compose</h2>

<p>Having the kafka image in our system we are ready to create a cluster. For <a href="https://zookeeper.apache.org/">Zookeeper</a> we will use the official image from <a href="https://hub.docker.com/_/zookeeper/">docker hub</a>. In the docker compose example I’ll create a 3 nodes kafka cluster, but any number of nodes can be added by adding a new entry and changing the name/hostname.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">docker-compose.yml</code></li>
</ul>

<pre><code class="language-YAML">version: '2.1'
services:
  zookeeper:
    hostname: zookeeper
    image: zookeeper:latest
    environment:
      ZOO_MY_ID: 1
    restart: always
    healthcheck:
        test: ["CMD", "zkServer.sh", "status"]

  kafka1:
    image: joseestudillo/kafka:latest
    hostname: kafka1
    environment:
      KAFKA_ZOOKEEPER_HOST: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      zookeeper:
        condition: service_healthy

  kafka2:
    image: joseestudillo/kafka:latest
    hostname: kafka2
    environment:
      KAFKA_ZOOKEEPER_HOST: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - kafka1

  kafka3:
    image: joseestudillo/kafka:latest
    hostname: kafka3
    environment:
      KAFKA_ZOOKEEPER_HOST: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - kafka1
</code></pre>

<p>In they YAML, I’ve defined a single node zookeeper (examples with a higher number of nodes can be found in docker hub). Notice that <a href="https://zookeeper.apache.org/">Zookeeper</a> must be running to be able to create a kafka cluster, to guarantee this, we will make the first <a href="https://kafka.apache.org/">Kafka</a> node (<code class="language-plaintext highlighter-rouge">kafka1</code>) depend on the <a href="https://zookeeper.apache.org/">Zookeeper</a> container, then the rest of the <a href="https://kafka.apache.org/">Kafka</a> nodes will depend of the first one that we will use as advertised host.</p>

<h2 id="running-the-cluster">Running the cluster</h2>

<p>Once the kafka image is on the system (check with <code class="language-plaintext highlighter-rouge">docker images</code>), we can launch the cluster using: <code class="language-plaintext highlighter-rouge">docker-compose up</code> that will show the logs from all the running containers. The status of the containers can be checked with <code class="language-plaintext highlighter-rouge">docker-compose ps</code> that as the rest of the docker compose commands, but be run from the directory where <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> is placed, or point explicitly to it.</p>

<p>The cluster then can be operated from any of its nodes: <code class="language-plaintext highlighter-rouge">docker-compose exec &lt;container name in the docker compose file&gt; bash</code></p>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><summary type="html"><![CDATA[Updated version of this article]]></summary></entry><entry><title type="html">Hosting an apache server in Openshift with a godaddy hosted domain</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/2015/08/04/hosting-apache-server-openshift-godaddy-domain/" rel="alternate" type="text/html" title="Hosting an apache server in Openshift with a godaddy hosted domain" /><published>2015-08-04T00:00:00+01:00</published><updated>2015-08-04T00:00:00+01:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/2015/08/04/hosting-apache-server-openshift-godaddy-domain</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/2015/08/04/hosting-apache-server-openshift-godaddy-domain/"><![CDATA[<h1 id="hosting-an-apache-server-in-openshift-with-a-godaddy-hosted-domain">Hosting an apache server in Openshift with a godaddy hosted domain</h1>

<p>In this article I’ll show how to point an existing domain hosted in godaddy to an apache server running in Openshift, to do so I’ll use the following generic URLs:</p>

<ul>
  <li>
    <p>Subdomain under you already registered domain: <code class="language-plaintext highlighter-rouge">http://SUBDOMAIN.DOMAIN.com</code></p>
  </li>
  <li>
    <p>URL to the apache server hosted in <a href="https://www.openshift.com/">OpenShift</a>: <code class="language-plaintext highlighter-rouge">http://APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com</code></p>
  </li>
</ul>

<p>And I will also assume you have a free account in <a href="https://www.openshift.com/">OpenShift</a>.</p>

<h2 id="creating-an-application">Creating an application</h2>

<p>Once logged into <a href="https://www.openshift.com/">OpenShift</a> go to: <strong>Applications -&gt; Add Application…</strong></p>

<p>In this case I will focus in creating a simple apache server. Configuring any other type of server should work in the same way. The apache server isn’t offered as an option, but any server that can host PHP will work (for example: PHP 5.3, PHP 5.4).</p>

<p>During the instantiation process, we will be asked to create an URL for the new application, in our case this will be: <code class="language-plaintext highlighter-rouge">http://APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com</code>. Unless you have specific needs, the rest of the parameters can be left as they are. A git repository can be given to obtaion the content, otherwise, one will be created for every application.</p>

<h2 id="uploading-files-to-the-application-using-git">Uploading files to the application using git</h2>

<p>In the right side hand of the application configuration menu, there is a box that displays the git repository associated to the app, for this example it would look like <code class="language-plaintext highlighter-rouge">ssh://ID@APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com/~/git/APPNAME.git/</code> using this URL we can clone the git repository from the CLI:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">git clone ssh://[ID]@APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com/~/git/APPNAME.git/</code></pre></figure>

<p>Once it has been cloned, we can place the required files into the directory <code class="language-plaintext highlighter-rouge">APPNAME</code>. The last step will be uploading the files, this can be done using the commands below:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">git add <span class="nt">--all</span>
git commit <span class="nt">-m</span> <span class="s2">"</span><span class="sb">`</span><span class="nb">date</span><span class="sb">`</span><span class="s2">"</span>
git push origin</code></pre></figure>

<p>Notice that for this to work you will need credentials, the easiest way to do it is having your public shh key configured in <a href="https://www.openshift.com/">OpenShift</a>. This is outside the scope of this article, so as a quick tip, <code class="language-plaintext highlighter-rouge">ssh-keygen -t rsa -b 4096 -C "your@email.com"</code> will generate the public key and <code class="language-plaintext highlighter-rouge">cat ~/.ssh/id_rsa.pub</code> will display it.</p>

<h3 id="setting-the-alias-domain">Setting the alias domain</h3>

<p>From the application configuration page, right next to the application’s URL, there is a link called <strong>change</strong>, clicking on it will take you to a menu where you can see two values:</p>

<ul>
  <li>
    <p><strong>Application URL</strong>: is the actual URL app, it should look like <code class="language-plaintext highlighter-rouge">http://APP_NAME-DOMAIN_NAME.rhcloud.com</code> (as defined before) and</p>
  </li>
  <li>
    <p><strong>Domain Name</strong>: which is the domain that will be pointing to this app, being in the case <code class="language-plaintext highlighter-rouge">SUBDOMAIN.DOMAIN.com</code>.</p>
  </li>
</ul>

<p>With this is setup, no further configuration is required on the <a href="https://www.openshift.com/">OpenShift</a> side.</p>

<h3 id="configuring-the-domain-in-godaddy">Configuring the domain in Godaddy</h3>

<p>To point our domain to a <a href="https://www.openshift.com/">OpenShift</a>’s application we need two things:</p>

<ul>
  <li>
    <p>redirect DOMAIN.com to SUBDOMAIN.DOMAIN.com</p>
  </li>
  <li>
    <p>add a CNAME entry to point SUBDOMAIN.DOMAIN.com to the <a href="https://www.openshift.com/">OpenShift</a> URL.</p>
  </li>
</ul>

<p>The redirection is done using forwarding at domain level (no subdomain!) so clicking in <strong>manage</strong> under the forwarding category should allow you to add an entry:</p>

<ul>
  <li>
    <p><strong>Forward To</strong>: http://SUBDOMAIN.DOMAIN.com</p>
  </li>
  <li>
    <p><strong>Redirect Type</strong>: 301 (Permanent)</p>
  </li>
  <li>
    <p><strong>Forward Settings</strong>: Forward only</p>
  </li>
</ul>

<p>Adding the CName entry is done from a different tab, <strong>DNS ZONE FILE</strong>, where you must check that under:</p>

<ul>
  <li>
    <p><strong>A (Host)</strong> : there is no entries for the subdomain you want to redirect, and, in</p>
  </li>
  <li>
    <p><strong>CName (Alias)</strong>: you add the entry:</p>

    <ul>
      <li>
        <p><em>Record Type</em>: CNAME (alias)</p>
      </li>
      <li>
        <p><em>Host</em>: SUBDOMAIN</p>
      </li>
      <li>
        <p><em>Points To</em>: http://APP_NAME-OPENSHIFT_DOMAIN_NAME.rhcloud.com</p>
      </li>
      <li>
        <p><em>TTL</em>: 1 hour</p>
      </li>
    </ul>
  </li>
</ul>

<p>If you got to this point you are all setup, after waiting a few minutes (this may vary) the page will be ready to use.</p>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><summary type="html"><![CDATA[Hosting an apache server in Openshift with a godaddy hosted domain]]></summary></entry><entry><title type="html">Exporting/Importing keyboard shortcuts in Linux Mint</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/linux/mint/2015/06/01/exporting-keybindings-linux-mint/" rel="alternate" type="text/html" title="Exporting/Importing keyboard shortcuts in Linux Mint" /><published>2015-06-01T00:00:00+01:00</published><updated>2015-06-01T00:00:00+01:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/linux/mint/2015/06/01/exporting-keybindings-linux-mint</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/linux/mint/2015/06/01/exporting-keybindings-linux-mint/"><![CDATA[<h1 id="exportingimporting-keyboard-shortcuts-in-linux-mint-cinnamon">Exporting/Importing keyboard shortcuts in Linux Mint (Cinnamon)</h1>

<p>To check the configuration of <a href="http://www.linuxmint.com/">Linux Mint Cinnamon Edition</a> we will need the command <code class="language-plaintext highlighter-rouge">dconf</code>, in case it isn’t be installed, use <code class="language-plaintext highlighter-rouge">sudo apt-get install dconf-cli</code></p>

<h2 id="see-the-current-configuration">See the current configuration</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dconf dump /org/cinnamon/
</code></pre></div></div>

<p>This will show all the entries under <code class="language-plaintext highlighter-rouge">/org/cinnamon/</code> which means not all the entries will be related the the keyboard shorcuts configuration, you can get specific entries using the complete path in <code class="language-plaintext highlighter-rouge">dconf</code></p>

<h2 id="exporting-the-current-configuration">Exporting the current configuration</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dconf dump /org/cinnamon/ <span class="o">&gt;</span> keyboard-shortcuts-conf.txt
</code></pre></div></div>

<p>In my case, using <a href="http://www.linuxmint.com/">Linux Mint 17</a>, I get many entries, but in this case we will only need the followings:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>settings-daemon/plugins/media-keys]
<span class="nv">terminal</span><span class="o">=</span><span class="s1">'&lt;Super&gt;t'</span>
<span class="nv">screensaver</span><span class="o">=</span><span class="s1">'&lt;Super&gt;l'</span>
<span class="nv">home</span><span class="o">=</span><span class="s1">'&lt;Super&gt;e'</span>

<span class="o">[</span>settings-daemon/peripherals/keyboard]
numlock-state<span class="o">=</span><span class="s1">'on'</span>

<span class="o">[</span>keybindings/custom-keybindings/custom0]
<span class="nv">binding</span><span class="o">=</span><span class="s1">'&lt;Super&gt;w'</span>
<span class="nb">command</span><span class="o">=</span><span class="s1">'/usr/bin/google-chrome-stable %U'</span>
<span class="nv">name</span><span class="o">=</span><span class="s1">'Internet Browser'</span>

<span class="o">[</span>keybindings]
custom-list<span class="o">=[</span><span class="s1">'custom0'</span><span class="o">]</span>

<span class="o">[</span>muffin/keybindings]
panel-run-dialog<span class="o">=[</span><span class="s1">'&lt;Alt&gt;F2'</span>, <span class="s1">'&lt;Super&gt;r'</span><span class="o">]</span>
<span class="nv">unmaximize</span><span class="o">=</span>@as <span class="o">[]</span>
toggle-fullscreen<span class="o">=[</span><span class="s1">'F11'</span>, <span class="s1">'&lt;Super&gt;f'</span><span class="o">]</span>
toggle-maximized<span class="o">=[</span><span class="s1">'&lt;Super&gt;m'</span><span class="o">]</span>
move-to-workspace-left<span class="o">=[</span><span class="s1">'&lt;Shift&gt;&lt;Super&gt;Left'</span><span class="o">]</span>
move-to-workspace-right<span class="o">=[</span><span class="s1">'&lt;Shift&gt;&lt;Super&gt;Right'</span><span class="o">]</span>
</code></pre></div></div>

<h2 id="importing-a-configuration-form-a-file">Importing a configuration form a file</h2>

<p>Using the file generated in the previous process <code class="language-plaintext highlighter-rouge">keyboard-shortcuts-conf.txt</code> you can do the following</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dconf load /org/cinnamon/ &lt; keyboard-shortcuts-conf.txt
</code></pre></div></div>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><category term="Linux" /><category term="Mint" /><summary type="html"><![CDATA[Exporting/Importing keyboard shortcuts in Linux Mint (Cinnamon)]]></summary></entry><entry><title type="html">Installing Oracle Database XE in CentOS 7</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/oracle/database/2014/12/24/installing-oracle-xe-database-centos-7/" rel="alternate" type="text/html" title="Installing Oracle Database XE in CentOS 7" /><published>2014-12-24T00:00:00+00:00</published><updated>2014-12-24T00:00:00+00:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/oracle/database/2014/12/24/installing-oracle-xe-database-centos-7</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/oracle/database/2014/12/24/installing-oracle-xe-database-centos-7/"><![CDATA[<h1 id="installing-oracle-database-xe-in-centos-7">Installing Oracle Database XE in CentOS 7</h1>

<h2 id="getting-the-binaries">Getting the binaries</h2>

<p>The binaries can be found in the link <a href="http://www.oracle.com/technetwork/database/database-technologies/express-edition/downloads/index.html">Oracle Database XE</a></p>

<p>At the time of this writing the name of the file is <code class="language-plaintext highlighter-rouge">oracle-xe-11.2.0-1.0.x86_64.rpm.zip</code> in linux this can be extracted using:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">unzip oracle-xe-11.2.0-1.0.x86_64.rpm.zip</code></pre></figure>

<p>Supposing the file have been extracted to <code class="language-plaintext highlighter-rouge">/tmp</code> the rpm file will be at <code class="language-plaintext highlighter-rouge">/tmp/Disk1/oracle-xe-11.2.0-1.0.x86_64.rpm</code></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#run as super user, su/sudo</span>
rpm <span class="nt">-Uvh</span> oracle-xe-11.2.0-1.0.x86_64.rpm </code></pre></figure>

<p>Output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Preparing...                          ################################# [100%]
Updating / installing...
   1:oracle-xe-11.2.0-1.0             ################################# [100%]
Executing post-install steps...
sh: -c: line 0: syntax error near unexpected token `('
sh: -c: line 0: `echo ~(unknown)'
You must run '/etc/init.d/oracle-xe configure' as the root user to configure the database.
</code></pre></div></div>

<p>Notice that despite the post-install script errors the installation is successful. I haven’t done much research about this yet.</p>

<p>After installing the app run:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">/etc/init.d/oracle-xe configure <span class="c">#run as super user</span></code></pre></figure>

<p>Oracle Database XE has a webapp associated to it, be default the offered port is <em>8080</em> but I will use <em>11521</em> to avoid conflict with other applications. For the database listener, I’ll keep 1521.</p>

<p>Output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@localhost Disk1]# /etc/init.d/oracle-xe configure

Oracle Database 11g Express Edition Configuration
-------------------------------------------------
This will configure on-boot properties of Oracle Database 11g Express 
Edition.  The following questions will determine whether the database should 
be starting upon system boot, the ports it will use, and the passwords that 
will be used for database accounts.  Press &lt;Enter&gt; to accept the defaults. 
Ctrl-C will abort.

Specify the HTTP port that will be used for Oracle Application Express [8080]:11521

Specify a port that will be used for the database listener [1521]:

Specify a password to be used for database accounts.  Note that the same
password will be used for SYS and SYSTEM.  Oracle recommends the use of 
different passwords for each database account.  This can be done after 
initial configuration:
Confirm the password:

Do you want Oracle Database 11g Express Edition to be started on boot (y/n) [y]:y

Starting Oracle Net Listener...Done
Configuring database...Done
Starting Oracle Database 11g Express Edition instance...Done
Installation completed successfully.
</code></pre></div></div>

<h2 id="managing-the-service">Managing the service</h2>

<p>The service file is located in <code class="language-plaintext highlighter-rouge">/etc/init.d/oracle-xe</code> and be started / stopped using:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">    
service oracle-xe start / service oracle-xe stop</code></pre></figure>

<h2 id="opening-ports-for-external-access">Opening Ports for external access</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>11521/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>1521/tcp
firewall-cmd <span class="nt">--reload</span></code></pre></figure>

<h2 id="first-use">First use</h2>

<p>Assuming we are using the same box to access to the webapp, we could use <a href="http://localhost:11521/">localhost:11521</a> and login as <strong>SYSTEM</strong>. You’ll notice that even typing the right password, the login won’t be successful, just cancel the login, and you will be redirected to a different URL, this only happens the first time.</p>

<h3 id="creating-a-workspace">Creating a workspace</h3>

<p>Once in APEX <a href="http://localhost:11521/">localhost:11521</a> go to <strong>home -&gt; Application express</strong> and create a workspace (<em>Application express workspace</em> it will be the name of the workspace)</p>

<p><img src="https://blog.joseestudillo.com/img/oracle-xe-database-centos-7/create-workspace.png" alt="creating oracle workspace" /></p>

<p>then connect to it using the interface next to the previous one to access to the newly created workspace</p>

<p><img src="https://blog.joseestudillo.com/img/oracle-xe-database-centos-7/login-workspace.png" alt="log into workspace" /></p>

<h2 id="connecting-from-java">Connecting from Java</h2>

<p>To connect from Java the oracle database driver is required, the oracle drivers are not hosted in Maven, so the easiest way to get it is from:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/u01/app/oracle/product/11.2.0/xe/jdbc/lib/ojdbc6.jar
</code></pre></div></div>

<p>To install one the drives to make it accessible from Maven check <a href="https://blog.joseestudillo.com/https://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven/">this</a>. With Oracle driver added to the classpath, the connection URL for this example would look as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jdbc:oracle:thin:@localhost:1521:xe
</code></pre></div></div>

<p>And very quick chunk of code to test the connection:</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Class</span><span class="o">.</span><span class="na">forName</span><span class="o">(</span><span class="s">"oracle.jdbc.driver.OracleDriver"</span><span class="o">);</span>
<span class="nc">Connection</span> <span class="n">conn</span> <span class="o">=</span> <span class="nc">DriverManager</span><span class="o">.</span><span class="na">getConnection</span><span class="o">(</span><span class="s">"jdbc:oracle:thin:@localhost:1521:xe"</span><span class="o">,</span> <span class="s">"dbuser"</span><span class="o">,</span> <span class="s">"YOUR_PASSWORD"</span><span class="o">);</span>
<span class="nc">Statement</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="na">createStatement</span><span class="o">();</span>
<span class="nc">ResultSet</span> <span class="n">resultSet</span> <span class="o">=</span> <span class="n">statement</span><span class="o">.</span><span class="na">executeQuery</span><span class="o">(</span><span class="s">"SELECT 1 FROM Dual"</span><span class="o">);</span>
<span class="k">if</span><span class="o">(</span><span class="n">resultSet</span><span class="o">.</span><span class="na">next</span><span class="o">())</span> <span class="o">{</span>
    <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Success"</span><span class="o">);</span>
<span class="o">}</span></code></pre></figure>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><category term="Oracle" /><category term="Database" /><summary type="html"><![CDATA[Installing Oracle Database XE in CentOS 7]]></summary></entry><entry><title type="html">Installing third party jars in Maven</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven/" rel="alternate" type="text/html" title="Installing third party jars in Maven" /><published>2014-12-23T00:00:00+00:00</published><updated>2014-12-23T00:00:00+00:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven/"><![CDATA[<h1 id="installing-third-party-jars-in-maven">Installing third party jars in Maven</h1>

<p>Some companies don’t put their jars in Maven official repositories, so when working in a local environment is useful to have this jars available as any other.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">	mvn <span class="nb">install</span>:install-file <span class="nt">-Dfile</span><span class="o">=</span>JAR_FILE_PATH <span class="nt">-DgroupId</span><span class="o">=</span>GROUP_ID <span class="nt">-DartifactId</span><span class="o">=</span>ARTIFACT_ID <span class="nt">-Dversion</span><span class="o">=</span>VERSION  <span class="nt">-Dpackaging</span><span class="o">=</span>jar</code></pre></figure>

<p>where:</p>

<ul>
  <li><strong>JAR_FILE_PATH</strong>: path to the jar file to install</li>
  <li><strong>GROUP_ID</strong>: Id to identify a group that will contains the jars released by the same provider (i.e. org.springframework)</li>
  <li><strong>ARTIFACT_ID</strong>: Id to identify a single jar file (i.e. spring-core)</li>
  <li><strong>VERSION</strong>: version of the specific jar (i.e. 1.2.0)</li>
</ul>

<p>to declare this new added jar in the pom.xml</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;project&gt;</span>
  ...
  <span class="nt">&lt;dependencies&gt;</span>
    ...
    <span class="nt">&lt;dependency&gt;</span>
      <span class="nt">&lt;groupId&gt;</span>GROUP_ID<span class="nt">&lt;/groupId&gt;</span>
      <span class="nt">&lt;artifactId&gt;</span>ARTIFACT_ID<span class="nt">&lt;/artifactId&gt;</span>
      <span class="nt">&lt;version&gt;</span>VERSION<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
    ...
  <span class="nt">&lt;/dependencies&gt;</span>
  ...
<span class="nt">&lt;/project&gt;</span></code></pre></figure>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><category term="[&quot;maven&quot;, &quot;java&quot;, &quot;jar&quot;]" /><summary type="html"><![CDATA[Installing third party jars in Maven]]></summary></entry><entry><title type="html">Installing Hadoop in CentOS 7</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/11/installing-hadoop-centos-7/" rel="alternate" type="text/html" title="Installing Hadoop in CentOS 7" /><published>2014-12-11T00:00:00+00:00</published><updated>2014-12-11T00:00:00+00:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/11/installing-hadoop-centos-7</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/11/installing-hadoop-centos-7/"><![CDATA[<h1 id="installing-hadoop-in-centos-7">Installing Hadoop in CentOS 7</h1>

<p>In this article I’m going to focus in how to install Hadoop in CentOS 7. At the time of this writing there are two mantanined version of Hadoop that can be useful for different purposes, for these reasons we will install both. For Hadoop 1, we will use <a href="http://mirror.ox.ac.uk/sites/rsync.apache.org/hadoop/common/stable1/hadoop-1.2.1.tar.gz">hadoop-1.2.1</a>, for Hadoop 2, <a href="http://mirror.ox.ac.uk/sites/rsync.apache.org/hadoop/common/stable2/hadoop-2.6.0.tar.gz">hadoop-2.6.0</a>. For other versions check <a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/">Hadoop Download Page</a>. Also worth notice that the hostname of the machine where I’m doing the instalation is <strong>centos-vm</strong> and I will use this name instead of <strong>localhost</strong> because this will make possible to work with this installation remotely.</p>

<h2 id="installing-hadoop">Installing Hadoop</h2>

<p>There are different installation choices, I prefer to stay with the binaries because it gives me all the control about what is configured and where. Depending on the linux distribution choosen, using the RPMs could be another good choice.</p>

<p>Because every version of Hadoop can introduce small changes this may not work in other versions, the best way to install it is following the instructions in the documentation included in the tar file.</p>

<p>For each Hadoop version we will create a folder <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop-x.y.z</code> and create a symbolic link <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoopx</code> that will make updates easier. In our case this translates into:</p>

<ul>
  <li>Hadoop 1
    <ul>
      <li><em>Directory</em>: <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop-1.2.1</code></li>
      <li><em>Symbolic link</em>: <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop1</code></li>
    </ul>
  </li>
  <li>Hadoop 2
    <ul>
      <li><em>Directory</em>: <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop-2.6.0</code></li>
      <li><em>Symbolic link</em>: <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop2</code></li>
    </ul>
  </li>
</ul>

<p>Before the installation we also need to create a user, a group and set the permissions:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># executed as super user</span>
  	
groupadd hadoop
useradd <span class="nt">-g</span> hadoop <span class="nt">-c</span> <span class="s2">"Hadoop user"</span> hadoop
<span class="nb">mkdir</span> /var/log/hadoop
<span class="nb">chown</span> <span class="nt">-R</span> hadoop:hadoop /var/log/hadoop
<span class="nb">chmod</span> <span class="nt">-R</span> u+xwr,g+xwr,o+xr /var/log/hadoop
<span class="nb">mkdir</span> /var/data/hadoop
<span class="nb">chown</span> <span class="nt">-R</span> hadoop:hadoop /var/data/hadoop
<span class="nb">chmod</span> <span class="nt">-R</span> u+xwr,g+xwr,o+xr /var/data/hadoop</code></pre></figure>

<p>After this we must set the new user to access to the host without authenticating. This can be checked with the command:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">ssh centos-vm</code></pre></figure>

<p>if you are asked for a password do the following:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"> <span class="c"># no parameters required (use default parameters)</span>

ssh-keygen 

 <span class="c"># copy the generated key (would also work for a remote server)</span>

ssh-copy-id <span class="nt">-i</span> ~/.ssh/id_rsa.pub centos-vm

 <span class="c"># stop the ssh session (exit) and try</span>

ssh centos-vm</code></pre></figure>

<p>With this steps you should be able to access to the server without typing the password, making easier to use Hadoop’s start/stop scripts.</p>

<h2 id="hadoop-1">Hadoop 1</h2>

<h3 id="tar-file-structure">Tar file structure</h3>

<p>The uncompressed tar file has the following structure for Hadoop 1:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hadoop-1.z.y/
├── bin
├── c++
├── conf
├── contrib
├── docs
├── ivy
├── lib
├── libexec
├── logs
├── sbin
├── share
├── src
└── webapps
</code></pre></div></div>

<p>The documentation for this version is in the <code class="language-plaintext highlighter-rouge">docs</code> directory. The details for the single node installation can be found in <code class="language-plaintext highlighter-rouge">docs/single_node_setup.html</code>. Apart of the installation process, authentication/access problems are their solutions are also  described in this document.</p>

<h3 id="editing-the-configuration-files-for-a-pseudo-distributed-configuration">Editing the configuration files for a Pseudo-distributed configuration</h3>

<p>The first step is to set the <code class="language-plaintext highlighter-rouge">JAVA_HOME</code> variable in <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop1/conf/hadoop-env.sh</code>. Different Hadoop versions may need different Java SDK versions, this versions table can be found <a href="http://wiki.apache.org/hadoop/HadoopJavaVersions">here</a>. I’m currently using Java 8 (1.8.0_25) and Hadoop is running without any issues. If at this point you don’t have Java in your system go to <a href="https://blog.joseestudillo.com/https://blog.joseestudillo.com/2014/10/14/installing-java-centos-7/">Installing Java in CentOS 7</a>.</p>

<p>Supposing that the right version of java is installed in <code class="language-plaintext highlighter-rouge">/usr/java/latest</code> the following command will change the configuration in the file <code class="language-plaintext highlighter-rouge">conf/hadoop-env.sh</code>. Notice that this may not be required is you already have the right JDK installed and the JAVA_HOME variable defined (check using <code class="language-plaintext highlighter-rouge">echo "$JAVA_HOME"</code>).</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s-^.*JAVA_HOME.*-export JAVA_HOME=/usr/java/latest-g"</span>  /opt/apache-hadoop/hadoop1/conf/hadoop-env.sh</code></pre></figure>

<p>In order to be a good linux citizen we will also configure the log path (<code class="language-plaintext highlighter-rouge">/var/log/hadoop</code>):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">    
<span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s-^.*HADOOP_LOG_DIR.*-export HADOOP_LOG_DIR=/var/log/hadoop-g"</span>  /opt/apache-hadoop/hadoop1/conf/hadoop-env.sh</code></pre></figure>

<p>For a <em>Pseudo-Distributed</em> configuration these files must also be modified:</p>

<ul>
  <li><strong>conf/core-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs://centos-vm:9000<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
  <li>
    <p><strong>conf/hdfs-site.xml</strong>:</p>

    <p>In the original Hadoop instructions, the properties below are not configured:</p>

    <ul>
      <li>dfs.name.dir</li>
      <li>dfs.data.dir</li>
      <li>dfs.client.buffer.dir</li>
      <li>mapred.local.dir</li>
    </ul>
  </li>
</ul>

<p>Without this the required file structures will be created by default in the <code class="language-plaintext highlighter-rouge">/tmp/</code> folder. This is not a good practice as some systems are configured to delete the content of this folder when the system restarts. To avoid this just configure any writable directory that will guaranty the persistence of the data. In the example below, we will assume this folder is <code class="language-plaintext highlighter-rouge">/var/data/hadoop</code>:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>     
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.name.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/dfs<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.data.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/data<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.client.buffer.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/buffer<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapred.local.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/mapred<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
  <li><strong>conf/mapred-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapred.job.tracker<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>centos-vm:9001<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<h3 id="initializing-hadoop">Initializing Hadoop</h3>

<p>Once all the configuration have been set, it is required to format the filesystem with the following command:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> /opt/apache-hadoop/hadoop1/bin
./hadoop namenode <span class="nt">-format</span></code></pre></figure>

<p>The output should be similar to:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>14/12/20 01:35:12 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = centos-vm/127.0.0.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_25
************************************************************/
14/12/20 01:35:12 INFO util.GSet: Computing capacity for map BlocksMap
14/12/20 01:35:12 INFO util.GSet: VM type       = 64-bit
14/12/20 01:35:12 INFO util.GSet: 2.0% max memory = 932184064
14/12/20 01:35:12 INFO util.GSet: capacity      = 2^21 = 2097152 entries
14/12/20 01:35:12 INFO util.GSet: recommended=2097152, actual=2097152
14/12/20 01:35:13 INFO namenode.FSNamesystem: fsOwner=hadoop
14/12/20 01:35:13 INFO namenode.FSNamesystem: supergroup=supergroup
14/12/20 01:35:13 INFO namenode.FSNamesystem: isPermissionEnabled=true
14/12/20 01:35:13 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
14/12/20 01:35:13 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
14/12/20 01:35:13 INFO namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
14/12/20 01:35:13 INFO namenode.NameNode: Caching file names occuring more than 10 times 
14/12/20 01:35:13 INFO common.Storage: Image file /home/hadoop/data/1/dfs/current/fsimage of size 112 bytes saved in 0 seconds.
14/12/20 01:35:13 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/home/hadoop/data/1/dfs/current/edits
14/12/20 01:35:13 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/home/hadoop/data/1/dfs/current/edits
14/12/20 01:35:13 INFO common.Storage: Storage directory /home/hadoop/data/1/dfs has been successfully formatted.
14/12/20 01:35:13 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at centos-vm/127.0.0.1
************************************************************/
</code></pre></div></div>

<p>This will using the folders structure configured previosly. When this step is done we are ready to start the system</p>

<h3 id="startingstopping-the-node">starting/stopping the node</h3>

<p>All the scrips to manage Hadoop can be also found in the <strong>bin</strong> folder (<code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop1/bin</code>)</p>

<ul>
  <li>Start the hadoop daemons:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">start-all.sh</code></pre></figure>

<ul>
  <li>To stop the node use:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">stop-all.sh</code></pre></figure>

<p>When the service is started, Hadoop offers web interfaces to know the status of the system:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NameNode - http://centos-vm:50070/
DataNode - http://centos-vm:50075/
JobTracker - http://centos-vm:50030/
</code></pre></div></div>

<h3 id="make-hadoop-web-interface-available-for-remote-access">Make Hadoop web interface available for remote access</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50070/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50075/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50030/tcp
firewall-cmd <span class="nt">--reload</span></code></pre></figure>

<h2 id="hadoop-2">Hadoop 2</h2>

<p>For Hadoop 2 some details are slightly different so we will go through them, Also the introduction of the new MapReduce engine, <a href="http://en.wikipedia.org/wiki/Apache_Hadoop">YARN</a>, will require some aditional configuration.</p>

<h3 id="tar-file-structure-1">Tar file structure</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hadoop-2.6.0/
├── bin
├── etc
├── include
├── lib
├── libexec
├── sbin
└── share
</code></pre></div></div>

<p>For this version the documentation is in <code class="language-plaintext highlighter-rouge">share/doc</code> and the single node installation in <code class="language-plaintext highlighter-rouge">share/doc/hadoop/hadoop-project-dist/hadoop-common/SingleCluster.html</code>.</p>

<h3 id="editing-the-configuration-files-for-a-pseudo-distributed-configuration-1">Editing the configuration files for a Pseudo-distributed configuration</h3>

<p>In the same way as we did for Hadoop 1, we may need to redefine JAVA_HOME, the <code class="language-plaintext highlighter-rouge">hadoop-env.sh</code> file has also been moved to another directory: <code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop2/etc/hadoop/hadoop-env.sh</code>. Because of the number of environment variables required to have a proper configuration I opted for defining then as a script in the <code class="language-plaintext highlighter-rouge">/etc/profile.d</code> directory</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">/etc/profile.d/hadoop.sh</code></li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">export </span><span class="nv">HADOOP_HOME</span><span class="o">=</span>/opt/apache-hadoop/default
<span class="nb">export </span><span class="nv">HADOOP</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>/bin
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$HADOOP</span>:<span class="nv">$PATH</span>

<span class="nb">export </span><span class="nv">HADOOP_PREFIX</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span><span class="nv">$HADOOP_PREFIX</span>/etc/hadoop
<span class="nb">export </span><span class="nv">HADOOP_YARN_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>

<span class="nb">export </span><span class="nv">NN_DATA_DIR</span><span class="o">=</span>/var/data/hadoop/hdfs/nn
<span class="nb">export </span><span class="nv">SNN_DATA_DIR</span><span class="o">=</span>/var/data/hadoop/hdfs/snn
<span class="nb">export </span><span class="nv">DN_DATA_DIR</span><span class="o">=</span>/var/data/hadoop/hdfs/dn
<span class="nb">export </span><span class="nv">YARN_LOG_DIR</span><span class="o">=</span>/var/log/hadoop/yarn
<span class="nb">export </span><span class="nv">HADOOP_LOG_DIR</span><span class="o">=</span>/var/log/hadoop/hdfs
<span class="nb">export </span><span class="nv">HADOOP_MAPRED_LOG_DIR</span><span class="o">=</span>/var/log/hadoop/mapred
<span class="nb">export </span><span class="nv">YARN_PID_DIR</span><span class="o">=</span>/var/run/hadoop/yarn
<span class="nb">export </span><span class="nv">HADOOP_PID_DIR</span><span class="o">=</span>/var/run/hadoop/hdfs
<span class="nb">export </span><span class="nv">HADOOP_MAPRED_PID_DIR</span><span class="o">=</span>/var/run/hadoop/mapred</code></pre></figure>

<p>this can also be defined on the <code class="language-plaintext highlighter-rouge">.bashrc</code> file in the hadoop user home directory.</p>

<ul>
  <li><strong>etc/hadoop/core-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs://centos-vm:9000<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
  <li><strong>etc/hadoop/hdfs-site.xml</strong>:</li>
</ul>

<p>Notice that in this version the file paths must be given as URIs.</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.name.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///var/data/hadoop/dfs<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.data.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///var/data/hadoop/dfs/data<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.client.buffer.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///var/data/hadoop/dfs/buffer<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapred.local.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file://var/data/hadoop/mapred<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
  <li><strong>etc/hadoop/mapred-site.xml</strong> (must be created or copied from <em>mapred-site.xml.template</em>):</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
  <li><strong>etc/hadoop/yarn-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<h3 id="initializing-hadoop-1">Initializing Hadoop</h3>

<p>The command to format the filesystem has been changed in Hadoop2:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> /opt/apache-hadoop/hadoop2/bin
./hdfs namenode <span class="nt">-format</span></code></pre></figure>

<h3 id="startingstopping-the-node-1">starting/stopping the node</h3>

<p>The directory where the scripts to start/stop that system has also change, being located now in the folder <strong>sbin</strong>  (<code class="language-plaintext highlighter-rouge">/opt/apache-hadoop/hadoop2/sbin</code>). Notice that for this version the <code class="language-plaintext highlighter-rouge">start-all.sh</code> and <code class="language-plaintext highlighter-rouge">stop-all.sh</code> have been deprecated. We will also need certain environment variables declared to make the configuration work, because this installation is only for development purposes, we will declare the environment variables in the startup script</p>

<ul>
  <li>Start Hadoop2:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">mkdir</span> <span class="nt">-p</span> /var/run/hadoop
<span class="nb">chown</span> <span class="nt">-R</span> hadoop:hadoop /var/run/hadoop
<span class="nb">echo</span> <span class="s2">"Starting Hadoop2 NameNode and DataNode"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/start-dfs.sh'</span>
<span class="nb">echo</span> <span class="s2">"Starting Hadoop2 YARN"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/start-yarn.sh'</span>
<span class="nb">echo</span> <span class="s2">"Starting Job History server"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/mr-jobhistory-daemon.sh start historyserver'</span></code></pre></figure>

<ul>
  <li>Stop Hadoop2:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">echo</span> <span class="s2">"Stopping Hadoop2 NameNode and DataNode"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/stop-dfs.sh'</span>
<span class="nb">echo</span> <span class="s2">"Stopping Hadoop2 YARN"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/stop-yarn.sh'</span>
<span class="nb">echo</span> <span class="s2">"Stopping Job History Server"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/mr-jobhistory-daemon.sh stop historyserver'</span></code></pre></figure>

<p>Once the service is started, Hadoop offers web interfaces to know the status of the system:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NameNode - http://centos-vm:50070/
DataNode - http://centos-vm:50075/
Cluster Metrics - http://centos-vm:8088/
Job History - http://centos-vm:19888/
NodeManager Information - http://centos-vm:8042/
</code></pre></div></div>

<h3 id="make-hadoop-web-interface-available-for-remote-access-1">Make Hadoop web interface available for remote access</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50070/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50075/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>8088/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>19888/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>8042/tcp
firewall-cmd <span class="nt">--reload</span></code></pre></figure>

<p><em>Updated 2015-03-16</em>: Configuration improved to use linux standards. Start / Stop script improved. New Ports to open added to the list.</p>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><summary type="html"><![CDATA[Installing Hadoop in CentOS 7]]></summary></entry><entry><title type="html">Installing MongoDB in CentOS 7</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/10/installing-mongodb-centos-7/" rel="alternate" type="text/html" title="Installing MongoDB in CentOS 7" /><published>2014-12-10T00:00:00+00:00</published><updated>2014-12-10T00:00:00+00:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/10/installing-mongodb-centos-7</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/10/installing-mongodb-centos-7/"><![CDATA[<h1 id="installing-mongodb-in-centos-7">Installing MongoDB in CentOS 7</h1>

<h1 id="adding-mongodb-repositories-to-yum">Adding MongoDB repositories to yum</h1>

<p>Following the steps specified in the [MongoDB installation guide][], we need to add mongo to the yum repository adding to <code class="language-plaintext highlighter-rouge">/etc/yum.repos.d/mongodb.repo</code> the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[mongodb]
name=MongoDB Repository
baseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/
gpgcheck=0
enabled=1
</code></pre></div></div>

<p>As <a href="TODO">super user</a> this file can be created using the command showed below:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">printf</span> <span class="s2">"[mongodb]</span><span class="se">\n</span><span class="s2">name=MongoDB Repository</span><span class="se">\n</span><span class="s2">baseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/</span><span class="se">\n</span><span class="s2">gpgcheck=0</span><span class="se">\n</span><span class="s2">enabled=1</span><span class="se">\n</span><span class="s2">"</span> <span class="o">&gt;</span> /etc/yum.repos.d/mongodb.repo</code></pre></figure>

<h1 id="installing-mongodb-with-yum">Installing MongoDB with yum</h1>

<p>Once the file have been created we can install MongoDB using yum:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># run as super user, su/sudo</span>
yum <span class="nb">install</span> <span class="nt">-y</span> mongodb-org</code></pre></figure>

<h1 id="configuring-mongodb">Configuring MongoDB</h1>

<p>By default, MongoDB configuration is stored in <code class="language-plaintext highlighter-rouge">/etc/mongodb.conf</code> there is not need to change anything to make it work. In the case external connections are required, the value <code class="language-plaintext highlighter-rouge">bind_ip=127.0.0.1</code> must be commented out. This can be done using:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># run as super user, su/sudo</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> s/bind_ip<span class="o">=</span>127.0.0.1/#bind_ip<span class="o">=</span>127.0.0.1/g /etc/mongod.conf</code></pre></figure>

<p>By default MongoDB is runining on the port 21017, so as part of allowing external access, this port must be opened in the firewall.</p>

<h1 id="opening-mongodb-ports-in-centos-7">Opening MongoDB ports in CentOS 7</h1>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>27017/tcp
firewall-cmd <span class="nt">--reload</span></code></pre></figure>

<h1 id="managing-mongodb-service">Managing MongoDB service</h1>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>service mongod start</code></pre></figure>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><summary type="html"><![CDATA[Installing MongoDB in CentOS 7]]></summary></entry><entry><title type="html">Configuring a Maven project hosted in Bitbucket in Jenkins</title><link href="http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/05/integrating-bitbucket-repo-jenkins/" rel="alternate" type="text/html" title="Configuring a Maven project hosted in Bitbucket in Jenkins" /><published>2014-12-05T00:00:00+00:00</published><updated>2014-12-05T00:00:00+00:00</updated><id>http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/05/integrating-bitbucket-repo-jenkins</id><content type="html" xml:base="http://joseestudillo.com/https://blog.joseestudillo.com/2014/12/05/integrating-bitbucket-repo-jenkins/"><![CDATA[<h1 id="configuring-a-maven-project-hosted-in-bitbucket">Configuring a Maven project hosted in Bitbucket</h1>

<p>If you don’t have Jenkins installed in  your system go to <a href="https://blog.joseestudillo.com/https://blog.joseestudillo.com/2014/12/03/installing-jenkins-centos-7/">How to install Jenkins</a></p>

<h2 id="installing-bitbucket-plugins">Installing Bitbucket plugins</h2>

<p>Manage Jenkins -&gt; Manage Plugins</p>

<p>Go to the <em>Available</em> tab and filter by “Bitbucket”, you will get the entries listed below:</p>

<ul>
  <li>Bitbucket OAuth Plugin</li>
  <li>Bitbucket Plugin</li>
  <li>Bitbucket Pullrequest Builder Plugin</li>
</ul>

<p>Not all this plugins are required to build from Bitbucket</p>

<h2 id="creating-new-item-for-a-maven-project-hosted-in-bitbucket">Creating new Item for a Maven project hosted in Bitbucket</h2>

<p>New Item -&gt; Maven Project</p>

<p>Maven project name:</p>

<ul>
  <li>Source Code Management
    <ul>
      <li>Repository URL</li>
      <li>Credentials</li>
      <li>Branches to build : */master (or any other specified)</li>
    </ul>
  </li>
  <li>Build Triggers
    <ul>
      <li>Build whenever a SNAPSHOT dependency is built</li>
      <li>Build when a change is pushed to BitBucket</li>
      <li>Build periodically: @midnight</li>
    </ul>
  </li>
  <li>Build
    <ul>
      <li>Root POM: pom.xml</li>
    </ul>
  </li>
  <li>Build Settings:
    <ul>
      <li>E-mail notification: setting the recipient and send emails for different cases, the most common one is for failed builds, so you can know as soon as a build fails.</li>
    </ul>
  </li>
</ul>]]></content><author><name>Jose Estudillo</name><email>jose@estudillo.me</email></author><summary type="html"><![CDATA[Configuring a Maven project hosted in Bitbucket]]></summary></entry></feed>