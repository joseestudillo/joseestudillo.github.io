<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Jose Estudillo's Blog. Software engineering and technology blog.">
    <meta name="keywords" content="jose,estudillo,ojeda,jose estudillo, jose estudillo ojeda,blog,programming,big data,software,engineering">
    <meta name="description" lang="en" content="Jose Estudillo's Blog. Software engineering and technology blog.">
    <meta name="description" lang="es" content="Blog de Jose Estudillo">

    <title>Installing Hadoop in CentOS 7</title>

    <link rel="canonical" href="http://blog.joseestudillo.com/2014/12/11/installing-hadoop-centos-7/">
    <link rel="icon" href="http://blog.joseestudillo.com/favicon.ico">
    <link rel="shortcut icon" href="http://blog.joseestudillo.com/favicon.ico">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="http://blog.joseestudillo.com/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="http://blog.joseestudillo.com/css/blog.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="http://blog.joseestudillo.com/css/syntax.css">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <link type="application/atom+xml" rel="alternate" href="http://joseestudillo.com/http://blog.joseestudillo.com/feed.xml" title="Jose Estudillo's Blog" />

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://blog.joseestudillo.com/">Jose Estudillo's Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="http://blog.joseestudillo.com/">Home</a>
                </li>
                
				
                <li>
                    <a href="http://blog.joseestudillo.com/about/">About</a>
                </li>
				
                
				
                <li>
                    <a href="http://blog.joseestudillo.com/books/">Books</a>
                </li>
				
                
				
                <li>
                    <a href="http://blog.joseestudillo.com/contact/">Contact</a>
                </li>
				
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('http://blog.joseestudillo.com/img/home-bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Installing Hadoop in CentOS 7</h1>
                    
                    <span class="meta">Posted by Jose Estudillo on December 11, 2014</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

				<h1>Installing Hadoop in CentOS 7</h1>

<p>In this article I&#39;m going to focus in how to install Hadoop in CentOS 7. At the time of this writing there are two mantanined version of Hadoop that can be useful for different purposes, for these reasons we will install both. For Hadoop 1, we will use <a href="http://mirror.ox.ac.uk/sites/rsync.apache.org/hadoop/common/stable1/hadoop-1.2.1.tar.gz">hadoop-1.2.1</a>, for Hadoop 2, <a href="http://mirror.ox.ac.uk/sites/rsync.apache.org/hadoop/common/stable2/hadoop-2.6.0.tar.gz">hadoop-2.6.0</a>. For other versions check <a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/">Hadoop Download Page</a>. Also worth notice that the hostname of the machine where I&#39;m doing the instalation is <strong>centos-vm</strong> and I will use this name instead of <strong>localhost</strong> because this will make possible to work with this installation remotely.</p>

<h2>Installing Hadoop</h2>

<p>There are different installation choices, I prefer to stay with the binaries because it gives me all the control about what is configured and where. Depending on the linux distribution choosen, using the RPMs could be another good choice. </p>

<p>Because every version of Hadoop can introduce small changes this may not work in other versions, the best way to install it is following the instructions in the documentation included in the tar file.</p>

<p>For each Hadoop version we will create a folder <code>/opt/apache-hadoop/hadoop-x.y.z</code> and create a symbolic link <code>/opt/apache-hadoop/hadoopx</code> that will make updates easier. In our case this translates into:</p>

<ul>
<li><p>Hadoop 1</p>

<ul>
<li><em>Directory</em>: <code>/opt/apache-hadoop/hadoop-1.2.1</code></li>
<li><em>Symbolic link</em>: <code>/opt/apache-hadoop/hadoop1</code></li>
</ul></li>
<li><p>Hadoop 2</p>

<ul>
<li><em>Directory</em>: <code>/opt/apache-hadoop/hadoop-2.6.0</code></li>
<li><em>Symbolic link</em>: <code>/opt/apache-hadoop/hadoop2</code></li>
</ul></li>
</ul>

<p>Before the installation we also need to create a user, a group and set the permissions:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># executed as super user</span>
    
groupadd hadoop
useradd <span class="nt">-g</span> hadoop <span class="nt">-c</span> <span class="s2">"Hadoop user"</span> hadoop
<span class="nb">mkdir</span> /var/log/hadoop
<span class="nb">chown</span> <span class="nt">-R</span> hadoop:hadoop /var/log/hadoop
<span class="nb">chmod</span> <span class="nt">-R</span> u+xwr,g+xwr,o+xr /var/log/hadoop
<span class="nb">mkdir</span> /var/data/hadoop
<span class="nb">chown</span> <span class="nt">-R</span> hadoop:hadoop /var/data/hadoop
<span class="nb">chmod</span> <span class="nt">-R</span> u+xwr,g+xwr,o+xr /var/data/hadoop</code></pre></figure>

<p>After this we must set the new user to access to the host without authenticating. This can be checked with the command:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">ssh centos-vm</code></pre></figure>

<p>if you are asked for a password do the following:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"> <span class="c"># no parameters required (use default parameters)</span>

ssh-keygen 

 <span class="c"># copy the generated key (would also work for a remote server)</span>

ssh-copy-id <span class="nt">-i</span> ~/.ssh/id_rsa.pub centos-vm

 <span class="c"># stop the ssh session (exit) and try</span>

ssh centos-vm</code></pre></figure>

<p>With this steps you should be able to access to the server without typing the password, making easier to use Hadoop&#39;s start/stop scripts.</p>

<h2>Hadoop 1</h2>

<h3>Tar file structure</h3>

<p>The uncompressed tar file has the following structure for Hadoop 1:</p>
<div class="highlight"><pre><code class="language-" data-lang="">hadoop-1.z.y/
├── bin
├── c++
├── conf
├── contrib
├── docs
├── ivy
├── lib
├── libexec
├── logs
├── sbin
├── share
├── src
└── webapps
</code></pre></div>
<p>The documentation for this version is in the <code>docs</code> directory. The details for the single node installation can be found in <code>docs/single_node_setup.html</code>. Apart of the installation process, authentication/access problems are their solutions are also  described in this document.</p>

<h3>Editing the configuration files for a Pseudo-distributed configuration</h3>

<p>The first step is to set the <code>JAVA_HOME</code> variable in <code>/opt/apache-hadoop/hadoop1/conf/hadoop-env.sh</code>. Different Hadoop versions may need different Java SDK versions, this versions table can be found <a href="http://wiki.apache.org/hadoop/HadoopJavaVersions">here</a>. I&#39;m currently using Java 8 (1.8.0_25) and Hadoop is running without any issues. If at this point you don&#39;t have Java in your system go to <a href="http://blog.joseestudillo.com/2014/10/14/installing-java-centos-7/">Installing Java in CentOS 7</a>.</p>

<p>Supposing that the right version of java is installed in <code>/usr/java/latest</code> the following command will change the configuration in the file <code>conf/hadoop-env.sh</code>. Notice that this may not be required is you already have the right JDK installed and the JAVA<em>HOME variable defined (check using `echo &quot;$JAVA</em>HOME&quot;`).</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s-^.*JAVA_HOME.*-export JAVA_HOME=/usr/java/latest-g"</span>  /opt/apache-hadoop/hadoop1/conf/hadoop-env.sh</code></pre></figure>
    

<p>In order to be a good linux citizen we will also configure the log path (<code>/var/log/hadoop</code>):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">    
<span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s-^.*HADOOP_LOG_DIR.*-export HADOOP_LOG_DIR=/var/log/hadoop-g"</span>  /opt/apache-hadoop/hadoop1/conf/hadoop-env.sh</code></pre></figure>

<p>For a <em>Pseudo-Distributed</em> configuration these files must also be modified:</p>

<ul>
<li><strong>conf/core-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs://centos-vm:9000<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>
  

<ul>
<li><strong>conf/hdfs-site.xml</strong>:</li>
</ul>

<p>In the original Hadoop instructions, the properties below are not configured:</p>

<ul>
<li>dfs.name.dir</li>
<li>dfs.data.dir</li>
<li>dfs.client.buffer.dir</li>
<li>mapred.local.dir</li>
</ul>

<p>Without this the required file structures will be created by default in the <code>/tmp/</code> folder. This is not a good practice as some systems are configured to delete the content of this folder when the system restarts. To avoid this just configure any writable directory that will guaranty the persistence of the data. In the example below, we will assume this folder is <code>/var/data/hadoop</code>:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>     
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.name.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/dfs<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.data.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/data<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.client.buffer.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/buffer<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapred.local.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/data/hadoop/mapred<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
<li><strong>conf/mapred-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapred.job.tracker<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>centos-vm:9001<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<h3>Initializing Hadoop</h3>

<p>Once all the configuration have been set, it is required to format the filesystem with the following command:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> /opt/apache-hadoop/hadoop1/bin
./hadoop namenode <span class="nt">-format</span></code></pre></figure>

<p>The output should be similar to:</p>
<div class="highlight"><pre><code class="language-" data-lang="">14/12/20 01:35:12 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = centos-vm/127.0.0.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_25
************************************************************/
14/12/20 01:35:12 INFO util.GSet: Computing capacity for map BlocksMap
14/12/20 01:35:12 INFO util.GSet: VM type       = 64-bit
14/12/20 01:35:12 INFO util.GSet: 2.0% max memory = 932184064
14/12/20 01:35:12 INFO util.GSet: capacity      = 2^21 = 2097152 entries
14/12/20 01:35:12 INFO util.GSet: recommended=2097152, actual=2097152
14/12/20 01:35:13 INFO namenode.FSNamesystem: fsOwner=hadoop
14/12/20 01:35:13 INFO namenode.FSNamesystem: supergroup=supergroup
14/12/20 01:35:13 INFO namenode.FSNamesystem: isPermissionEnabled=true
14/12/20 01:35:13 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
14/12/20 01:35:13 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
14/12/20 01:35:13 INFO namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
14/12/20 01:35:13 INFO namenode.NameNode: Caching file names occuring more than 10 times 
14/12/20 01:35:13 INFO common.Storage: Image file /home/hadoop/data/1/dfs/current/fsimage of size 112 bytes saved in 0 seconds.
14/12/20 01:35:13 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/home/hadoop/data/1/dfs/current/edits
14/12/20 01:35:13 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/home/hadoop/data/1/dfs/current/edits
14/12/20 01:35:13 INFO common.Storage: Storage directory /home/hadoop/data/1/dfs has been successfully formatted.
14/12/20 01:35:13 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at centos-vm/127.0.0.1
************************************************************/
</code></pre></div>
<p>This will using the folders structure configured previosly. When this step is done we are ready to start the system</p>

<h3>starting/stopping the node</h3>

<p>All the scrips to manage Hadoop can be also found in the <strong>bin</strong> folder (<code>/opt/apache-hadoop/hadoop1/bin</code>)</p>

<ul>
<li>Start the hadoop daemons:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">start-all.sh</code></pre></figure>

<ul>
<li>To stop the node use:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">stop-all.sh</code></pre></figure>
      

<p>When the service is started, Hadoop offers web interfaces to know the status of the system:</p>
<div class="highlight"><pre><code class="language-" data-lang="">NameNode - http://centos-vm:50070/
DataNode - http://centos-vm:50075/
JobTracker - http://centos-vm:50030/
</code></pre></div>
<h3>Make Hadoop web interface available for remote access</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50070/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50075/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50030/tcp
firewall-cmd <span class="nt">--reload</span></code></pre></figure>

<h2>Hadoop 2</h2>

<p>For Hadoop 2 some details are slightly different so we will go through them, Also the introduction of the new MapReduce engine, <a href="http://en.wikipedia.org/wiki/Apache_Hadoop">YARN</a>, will require some aditional configuration.</p>

<h3>Tar file structure</h3>
<div class="highlight"><pre><code class="language-" data-lang="">hadoop-2.6.0/
├── bin
├── etc
├── include
├── lib
├── libexec
├── sbin
└── share
</code></pre></div>
<p>For this version the documentation is in <code>share/doc</code> and the single node installation in <code>share/doc/hadoop/hadoop-project-dist/hadoop-common/SingleCluster.html</code>.</p>

<h3>Editing the configuration files for a Pseudo-distributed configuration</h3>

<p>In the same way as we did for Hadoop 1, we may need to redefine JAVA_HOME, the <code>hadoop-env.sh</code> file has also been moved to another directory: <code>/opt/apache-hadoop/hadoop2/etc/hadoop/hadoop-env.sh</code>. Because of the number of environment variables required to have a proper configuration I opted for defining then as a script in the <code>/etc/profile.d</code> directory</p>

<ul>
<li><code>/etc/profile.d/hadoop.sh</code></li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">export </span><span class="nv">HADOOP_HOME</span><span class="o">=</span>/opt/apache-hadoop/default
<span class="nb">export </span><span class="nv">HADOOP</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>/bin
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$HADOOP</span>:<span class="nv">$PATH</span>

<span class="nb">export </span><span class="nv">HADOOP_PREFIX</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span><span class="nv">$HADOOP_PREFIX</span>/etc/hadoop
<span class="nb">export </span><span class="nv">HADOOP_YARN_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>

<span class="nb">export </span><span class="nv">NN_DATA_DIR</span><span class="o">=</span>/var/data/hadoop/hdfs/nn
<span class="nb">export </span><span class="nv">SNN_DATA_DIR</span><span class="o">=</span>/var/data/hadoop/hdfs/snn
<span class="nb">export </span><span class="nv">DN_DATA_DIR</span><span class="o">=</span>/var/data/hadoop/hdfs/dn
<span class="nb">export </span><span class="nv">YARN_LOG_DIR</span><span class="o">=</span>/var/log/hadoop/yarn
<span class="nb">export </span><span class="nv">HADOOP_LOG_DIR</span><span class="o">=</span>/var/log/hadoop/hdfs
<span class="nb">export </span><span class="nv">HADOOP_MAPRED_LOG_DIR</span><span class="o">=</span>/var/log/hadoop/mapred
<span class="nb">export </span><span class="nv">YARN_PID_DIR</span><span class="o">=</span>/var/run/hadoop/yarn
<span class="nb">export </span><span class="nv">HADOOP_PID_DIR</span><span class="o">=</span>/var/run/hadoop/hdfs
<span class="nb">export </span><span class="nv">HADOOP_MAPRED_PID_DIR</span><span class="o">=</span>/var/run/hadoop/mapred</code></pre></figure>

<p>this can also be defined on the <code>.bashrc</code> file in the hadoop user home directory.</p>

<ul>
<li><strong>etc/hadoop/core-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs://centos-vm:9000<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
<li><strong>etc/hadoop/hdfs-site.xml</strong>:</li>
</ul>

<p>Notice that in this version the file paths must be given as URIs.</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.name.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///var/data/hadoop/dfs<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.data.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///var/data/hadoop/dfs/data<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.client.buffer.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///var/data/hadoop/dfs/buffer<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapred.local.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file://var/data/hadoop/mapred<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<ul>
<li><strong>etc/hadoop/mapred-site.xml</strong> (must be created or copied from <em>mapred-site.xml.template</em>):</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>
  

<ul>
<li><strong>etc/hadoop/yarn-site.xml</strong>:</li>
</ul>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
  <span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span></code></pre></figure>

<h3>Initializing Hadoop</h3>

<p>The command to format the filesystem has been changed in Hadoop2:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> /opt/apache-hadoop/hadoop2/bin
./hdfs namenode <span class="nt">-format</span></code></pre></figure>
    

<h3>starting/stopping the node</h3>

<p>The directory where the scripts to start/stop that system has also change, being located now in the folder <strong>sbin</strong>  (<code>/opt/apache-hadoop/hadoop2/sbin</code>). Notice that for this version the <code>start-all.sh</code> and <code>stop-all.sh</code> have been deprecated. We will also need certain environment variables declared to make the configuration work, because this installation is only for development purposes, we will declare the environment variables in the startup script</p>

<ul>
<li>Start Hadoop2:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">mkdir</span> <span class="nt">-p</span> /var/run/hadoop
<span class="nb">chown</span> <span class="nt">-R</span> hadoop:hadoop /var/run/hadoop
<span class="nb">echo</span> <span class="s2">"Starting Hadoop2 NameNode and DataNode"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/start-dfs.sh'</span>
<span class="nb">echo</span> <span class="s2">"Starting Hadoop2 YARN"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/start-yarn.sh'</span>
<span class="nb">echo</span> <span class="s2">"Starting Job History server"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/mr-jobhistory-daemon.sh start historyserver'</span></code></pre></figure>

<ul>
<li>Stop Hadoop2:</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">echo</span> <span class="s2">"Stopping Hadoop2 NameNode and DataNode"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/stop-dfs.sh'</span>
<span class="nb">echo</span> <span class="s2">"Stopping Hadoop2 YARN"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/stop-yarn.sh'</span>
<span class="nb">echo</span> <span class="s2">"Stopping Job History Server"</span>
su - hadoop <span class="nt">-c</span> <span class="s1">'/opt/apache-hadoop/hadoop2/sbin/mr-jobhistory-daemon.sh stop historyserver'</span></code></pre></figure>

<p>Once the service is started, Hadoop offers web interfaces to know the status of the system:</p>
<div class="highlight"><pre><code class="language-" data-lang="">NameNode - http://centos-vm:50070/
DataNode - http://centos-vm:50075/
Cluster Metrics - http://centos-vm:8088/
Job History - http://centos-vm:19888/
NodeManager Information - http://centos-vm:8042/
</code></pre></div>
<h3>Make Hadoop web interface available for remote access</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50070/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>50075/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>8088/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>19888/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--zone</span><span class="o">=</span>public <span class="nt">--add-port</span><span class="o">=</span>8042/tcp
firewall-cmd <span class="nt">--reload</span></code></pre></figure>

<p><em>Updated 2015-03-16</em>: Configuration improved to use linux standards. Start / Stop script improved. New Ports to open added to the list.</p>


                <hr>

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="http://blog.joseestudillo.com/2014/12/10/installing-mongodb-centos-7/" data-toggle="tooltip" data-placement="top" title="Installing MongoDB in CentOS 7">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="http://blog.joseestudillo.com/maven/java/jar/2014/12/23/installing-third-party-jars-in-maven/" data-toggle="tooltip" data-placement="top" title="Installing third party jars in Maven">Next Post &rarr;</a>
                    </li>
                    
                </ul>

            </div>
        </div>
        <div class="row">
          <!-- Disqus { -->
          <div class="text-center">
            <div id="disqus_thread"></div>
          </div>
          <!-- } Disqus -->
        </div>
    </div>
</article>
<script type="text/javascript" src="http://blog.joseestudillo.com/js/disqus.js"></script>

<hr>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="http://blog.joseestudillo.com/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="https://twitter.com/jose_estudillo">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/joseestudillo">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://linkedin.com/in/joseestudilloojeda">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="mailto:jose@estudillo.me">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Jose Estudillo Ojeda 2018</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="http://blog.joseestudillo.com/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="http://blog.joseestudillo.com/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="http://blog.joseestudillo.com/js/blog.min.js "></script>

<!-- Add This script -->

<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-51ff8808639bd279"></script>
<script type="text/javascript">
  var addthis_config = addthis_config||{};
  addthis_config.data_track_addressbar = false;
  addthis_config.data_track_clickback = false;
</script>



    


</body>

</html>
